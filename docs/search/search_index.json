{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome \u00b6 This site is devoted to the art of livecoding and algorithmic composition. About Livecoding \u00b6 Live coding (sometimes referred to as 'on-the-fly programming', 'just in time programming' and related term 'live programming') is a programming practice centred upon the use of improvised interactive programming. Live coding is often used to create sound and image based digital media, and is particularly prevalent in computer music, combining algorithmic composition with improvisation. -- Wikipedia https://en.wikipedia.org/wiki/Live_coding About me \u00b6 My name is Michele Pasin and I love tinkering with real-time computer languages that can produce music, mostly using the Impromptu and its successor Extempore languages. In this blog I report on musical compositions and experiments I've made, interesting livecoding resources and occasionally other inspiring stuff from the creative world. The Extempore language \u00b6 Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world. The Impromptu language \u00b6 Impromptu was the OSX-only predecessor of Extempore. Impromptu is an OSX programming language and environment for composers, sound artists, VJ's and graphic artists with an interest in live or interactive programming. Impromptu is a Scheme language environment, a member of the Lisp family of languages. Impromptu is used by artist-programmers in livecoding performances around the globe.","title":"Welcome"},{"location":"#welcome","text":"This site is devoted to the art of livecoding and algorithmic composition.","title":"Welcome"},{"location":"#about-livecoding","text":"Live coding (sometimes referred to as 'on-the-fly programming', 'just in time programming' and related term 'live programming') is a programming practice centred upon the use of improvised interactive programming. Live coding is often used to create sound and image based digital media, and is particularly prevalent in computer music, combining algorithmic composition with improvisation. -- Wikipedia https://en.wikipedia.org/wiki/Live_coding","title":"About Livecoding"},{"location":"#about-me","text":"My name is Michele Pasin and I love tinkering with real-time computer languages that can produce music, mostly using the Impromptu and its successor Extempore languages. In this blog I report on musical compositions and experiments I've made, interesting livecoding resources and occasionally other inspiring stuff from the creative world.","title":"About me"},{"location":"#the-extempore-language","text":"Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world.","title":"The Extempore language"},{"location":"#the-impromptu-language","text":"Impromptu was the OSX-only predecessor of Extempore. Impromptu is an OSX programming language and environment for composers, sound artists, VJ's and graphic artists with an interest in live or interactive programming. Impromptu is a Scheme language environment, a member of the Lisp family of languages. Impromptu is used by artist-programmers in livecoding performances around the globe.","title":"The Impromptu language"},{"location":"latest/","text":"Latest posts \u00b6","title":"Latest Posts"},{"location":"latest/#latest-posts","text":"","title":"Latest posts"},{"location":"archive/2007/2007-01-22-hand-controlled-wah/","tags":["guitar","music"],"text":"News for all the guitarists and music technology lovers: the Source Audio Hot Hand motion control for guitar effects. An innovative way to control the guitar sound in a theremin -like manner! Amazon lets you buy it for only 300$ now! Watch the video below to see it in action... The Hot Hand system is a patent pending technology that uses micro-machined motion sensors to translate movement and position into control signals for use in guitar effects. The system provides an unprecedented level of control and expressiveness and offers the artist a new way of manipulating effects.","title":"Hand-controlled Wah"},{"location":"archive/2007/2007-02-22-songbird-makes-a-big-difference/","text":"Songbird : I'm enjoying the whole of the web + my usual music library, underneath a music player. And the two things are integrated! Plus thousands of radios and podcasts handy... I guess it's going to be the next big revolution :-) And the list of features cant be reported: too long.","title":"Songbird makes a big difference"},{"location":"archive/2007/2007-05-12-impromptu-scheme-based-music-and-video/","text":"In one word? SUPER COOL!!! Impromptu is an OSX programming environment for composers, sound artists, VJ's and graphic artists with an interest in live or interactive programming. Impromptu is a Scheme language environment, a member of the Lisp family of languages. Time plays a major role in the Impromptu environment allowing accurate real-time scheduling of events and code. Impromptu is a dynamic environment designed for the creation and manipulation of running programs in live performance. Impromptu is a programmable AudioUnit host. A powerful environment for creating AudioUnit graphs of arbitrary complexity with precise programmatic control over individual AU nodes. Musical material can be precisely scheduled for performance by any AudioUnit instrument node and parameters, program changes and presets can be programmatically changed on-the-fly as well as directly via the AU's user interface. Graphics routines can be applied with the same temporal accuracy as audio material allowing artists to tightly integrate audio and visual components. OpenGL, live video processing, vector drawing routines, image rendering, CoreImage filters, text rendering and quicktime movie support are a few of the graphics features available for artists to play with. Impromptu also includes a bidirectional ObjC-Bridge allowing Scheme to instantiate and call ObjC objects and ObjC objects to call back into the Scheme interpreter.","title":"Impromptu : scheme-based music and video"},{"location":"archive/2007/2007-09-28-jamendo-free-and-quality-music-online/","tags":["jamendo","music","sharing","web2"],"text":"Jamendo is a new model for artists to promote, publish, and be paid for their music. I've used this new service for a couple of hours only but I already like it a lot\u2026 .. can it be because the Kryos Project are already in it? On jamendo, the artists distribute their music under Creative Commons licenses. In a nutshell, they allow you to download, remix and share their music freely. It's a \"Some rights reserved\" agreement, perfectly suited for the new century. These new rules allow jamendo to use the powerful new means of digital distribution like Peer-to-Peer networks such as BitTorrent or eMule to legally distribute albums at near-zero cost. jamendo users can discover and share albums, but also review them or start a discussion on the forums. Albums are democratically rated based on the visitors\u00e2\u20ac\u2122 reviews. If they fancy an artist they can support him by making a donation. jamendo is the only platform that joins together : A legal framework protecting the artists (thanks to the Creative Commons licenses). Free, simple and quick access to the music, for everyone. The use of the lastest Peer-to-Peer technologies The possibility of making direct donations to the artists. An adaptive music recommendation system based on iRATE to help listeners discover new artists based on their tastes and on other criterias such as their location.","title":"Jamendo: free and quality music online"},{"location":"archive/2009/2009-01-07-musicbox-maps-future-for-managing-large-music-collections/","tags":["music","visualization"],"text":"MIT student Anita Lillies shows off her project Music Box:","title":"MusicBox: Mapping and visualizing music collections"},{"location":"archive/2009/2009-01-28-guitar-rig-3-demo-audio-line-in-glitch-fixed/","tags":["guitar"],"text":"The other day I decided to have a go with the already-famous Guitar Rig 3 (a music production software for guitarists, including amplifiers, effects etc etc). Here's the official blurb: GUITAR RIG 3 is the ultimate all-in-one guitar and bass solution. Simply connect your guitar with your computer via the enhanced Rig Kontrol 3 foot pedal and you are ready to go. The on-board studio-quality soundcard routes the signal to your speakers, while the s oftware grants you access to an incredible number of perfectly modeled classic amps, cabinets, mics and effects - all arranged in a super-simple drag-and-drop rack format. Any style, any time - the perfect solution for professional studio and live setups. From the Native Instrument site you can download a demo version , so I did and set off to have some fun with my guitar.. obviously I didn't have the Rig Kontrol 3 foot pedal, but the instructions said it was possible to use the software just as a virtual instrument - that is by plugging your guitar directly into the line-in of the mac (as I don't have an external audio interface yet). Unfortunately it wasn't that easy - the audio controls of Guitar Rig didn't allow me to choose my mac's LineIn, so no sound at all !!! I googled the issue quite a bit, found out that other people run into the same problem . Thus I emailed directly the guys at Native Instruments, and (I wasnt expecting this) they got back to me after a couple of days!!! Thanks Nadine! Here's their feedback - thought it could have been useful to other mac users: In order to fix this problem, please create an \"Aggregate Device\". An Aggregate Device is an audio interface that virtually exists in your computer. It uses audio inputs and outputs of one or more real audio interfaces which are connected to your computer. How to setup a generated device: - Open the OS X \"Audio and MIDI setup\" (MacHD/Applications/Utilities) and click on Audio -> Open aggregate device editor. - By clicking on the \"+\" button you can add a new device. Below you should see a list of real audio interfaces currently connected to your computer. Click on the check box to enable interfaces as needed for this aggregate device. Close the editor when done. - In the Audio settings window of the audio application you can now choose this \"aggregate device\" as your output device. - For Native Instruments standalone applications also setup the inputs and outputs as necessary under the Audio settings window/tab Routing. Nadine, Native Instruments Support Team I didn't know anything about Aggregate Audio , it's really really nice. For example it lets you manage your audio-input ports in such a way that you can use more than one at the same time, e.g. recording more than one instrument at the same time with Garage Band . So I tried to create a 'virtual' audio device using the Aggregate Device menu-option in the Audio-Midi-Setup utility ( update 22/11/09: if you're on SnowLeopard the Audio-Midi-Setup app looks a bit different, but what follows is till valid!). Unfortunately it didn't let me do that - every time I was making some changes to these settings they were not stored properly (on SnowLeopard the newly created device flashes and disappears every time). Some more googling, got an answer here . It's an issue with unix privileges on the .GlobalSettings.plist file (in /Library/Preferences ). Even if I'm an admin user, for some reasons the system doens't let me change that file, so I can't change the Aggregate Device options too. After trying various options suggested in this apple forum, I discovered that the only solution that worked for me was changing the privileges on the Preferences folder. I know, it's not really advisable to allow any user to change those prefs - but I took he risk.. I'm usually the only one using this mac. So if this is not the case for you, better look for another option.. That's it - now all you have to do is change the settings in GuitarRig : GUITAR RIG ROCKS!!!!!!!!!! Seriously thinking about buying the whole package!!!","title":"Guitar Rig 3 Demo - Audio Line-In glitch fixed!!"},{"location":"archive/2009/2009-05-07-soundmanager-2-makes-it-easier-to-play-sounds-using-javascript/","tags":["audio","javascript"],"text":"By wrapping and extending Flash 8's sound API, SoundManager 2 brings solid audio functionality to Javascript. Basic API Features (Flash 8 ) \u00b6 Load, stop, play, pause, mute, seek, pan and volume control of sounds from Javascript Events: onload, whileloading, whileplaying, onfinish and more ID3V1 and ID3V2 tag support for MP3s (title, artist, genre etc.) Shiny Flash 9 Features \u00b6 Full-screen MPEG-4 video (HE-AAC/H.264) and audio support \"MultiShot\" play (layered/chorusing effects) Waveform/frequency spectrum data Peak (L/R channel volume) data Audio buffering state/event handling","title":"SoundManager 2 makes it easier to play sounds using Javascript"},{"location":"archive/2009/2009-05-07-soundmanager-2-makes-it-easier-to-play-sounds-using-javascript/#basic-api-features-flash-8","text":"Load, stop, play, pause, mute, seek, pan and volume control of sounds from Javascript Events: onload, whileloading, whileplaying, onfinish and more ID3V1 and ID3V2 tag support for MP3s (title, artist, genre etc.)","title":"Basic API Features (Flash 8 )"},{"location":"archive/2009/2009-05-07-soundmanager-2-makes-it-easier-to-play-sounds-using-javascript/#shiny-flash-9-features","text":"Full-screen MPEG-4 video (HE-AAC/H.264) and audio support \"MultiShot\" play (layered/chorusing effects) Waveform/frequency spectrum data Peak (L/R channel volume) data Audio buffering state/event handling","title":"Shiny Flash 9 Features"},{"location":"archive/2009/2009-05-12-the-ibm-glass-engine/","tags":["minimalism","visualization"],"text":"The IBM Glass Engine enables deep navigation of the music of Philip Glass . Personal interests, associations, and impulses guide the listener through an expanding selection of over sixty Glass works. Philip Morris Glass (born January 31, 1937) is an American music composer. He is considered one of the most influential composers of the late-20th century and is widely acknowledged as a composer who has brought art music to the public (along with precursors such as Richard Strauss, Kurt Weill and Leonard Bernstein). Although his music is often, though controversially, described as minimalist , he distances himself from this label, describing himself instead as a composer of \"music with repetitive structures.\" Although his early, mature music is minimalist, he has evolved stylistically. Currently, he describes himself as a \"Classicist\", pointing out that he trained in harmony and counterpointFranz Schubert, Johann Sebastian Bach and Wolfgang Mozart with Nadia Boulanger. The engine is currently compatible with MS internet Explorer 6 & 7, and Firefox 2 on Windows, and Safari and Firefox on Mac OS X. Medium to high-bandwidth Internet access is highly recommended.","title":"The IBM glass engine"},{"location":"archive/2009/2009-06-23-algorithmic-music-exercise-1/","tags":["algorithmiccomposition","impromptu"],"text":"... I finally managed to find time to play more seriously with the fantastic impromptu - here's a first screencast , it doesn't sound that good but it made my day! (and maybe it'll help others better understand how impromptu works..) p.s. I'm intending to start posting more stuff about impromptu (e.g. little libraries and code samples), stay tuned!","title":"Algorithmic music: exercise #1"},{"location":"archive/2009/2009-08-26-michael-nymans-concert/","tags":["concert","minimalism"],"text":"I went to the BBC proms last night, to see Michael Nyman 's performance. It's been a delightful hour, such inspiring and intriguing melodies , really worth it! I really love the way minimalistic ideas crop up all the time, but always with a dense and emotional touch. And the Royal Albert Hall is an outstanding venue too.. After more than 40 years in the vanguard of British music as a composer, pianist, librettist and musicologist, Michael Nyman has been honoured with his first BBC Proms concert . The concert, part of the 115th Proms season, will take place at the Albert Hall, London on Aug 25 and features the World Premiere of a new piece entitled The Musicologist Scores commissioned by the BBC and music from Draughtman\u2019s Contract, Celan Songs and Memorial with guest soloist Anu Komsi in a programme that will commemorate two key dates in musical history - the 350th anniversary of Purcell\u2019s birth and the 250th anniversary of the death of Handel. Both were key influences on Nyman, who edited scores by the two composers as a PhD student under Thurston Dart in the 1960s [at Kings College!!]. \u201cA BBC Prom is obviously something that any composer hopes will happen one day,\u2019\u2019 Nyman says. \u2018\u2018The concert self-evidently commemorates the two giants of English baroque music. But coincidentally it also celebrates my own relationship with the work of the two composers,\u2019\u2019 Nyman says. \u201cA concert combining the music I have composed directly their work - the Purcell-based \u2018The Draughtsman\u2019s Contract\u2019 and \u2018The Cook, The Thief, His Wife and Her Lover\u2019 and the Handel-based \u2018The Musicologist Scores\u2019 seems entirely appropriate.\u2019\u2018 This is the list of songs played last night: The Draughtsman\u2019s Contract \u2013 selection 23\u2019 The Musicologist Scores c20\u2019 BBC commission: world premiere Six Celan Songs \u2013 Blume; Psalm 10\u2019 The Cook, The Thief, His Wife and Her Lover \u2013 Memorial 12\u2019 ANd the lineup: Anu Komsi soprano Michael Nyman Band Michael Nyman director/piano ...","title":"Michael Nyman's concert"},{"location":"archive/2009/2009-10-07-new-impromptu-screencast/","tags":["algorithmiccomposition","impromptu","livecoding"],"text":"... Initially this song was called ' Voices Slowly Talk To Me ' - then.. as usual.. I lost control of its direction! So I don't know anymore how much the title would apply. Anyways, it's my second experiment with recording an Impromptu performance (by the way I also played it live the other night at the Shunt in London, with various mistakes and delays, but somehow I got to the end - thanks to the toplap crew for their support!). Somehow I'm becoming wiser with doing this type of stuff, you know, just trying to learn from past experiences. So here're a few tips I matured in the last weeks: keep it simple . Especially when playing live. Long and convoluted functions are a giant source of errors especially when you're a bit tense use 'paste' templates . Stuff like the pb:cb function that comes by default with Impromptu. At the beginning I thought it wouldn't look too good, cause you've gotta show that you're coding the whole thing from scratch. But actually, when you're livecoding time is very very precious and what you want to focus on is sound, primarily (well at least this is what I like to do). It's also important to remember that many other environments for live performance are much much higher level than Impromptu - meaning that it's quicker to emit sounds or musical structures and change their properties... so let's make sure we're not comparing apple and oranges here! make variations often . Even if they look stupid to you, change something, add another melody, double the drumkit, stuff like that. The audience is more interested in new audio-visual things happening that in seeing you code a Bach's prelude. exercise a lot . I initially felt weird about this, mainly because playing with Impromptu means coding, and when I code I usually take my time and think. But livecoding transforms the coding practice into a musical performance. Which means that you don't have time to think, things should just come out automatically and sound good. Only then you can take the freedom of 'jamming' without a plan. I play guitar, and that's exactly how it works there... I must have forgotten about it. When playing a song I can't lose time trying to remember how to lay out the fingers on the neck, that has to happen automatically. That's it for now - I'll touch base again about this when the next live coding performance will happen! Rock on live-coders!","title":"New Impromptu screencast and a few lessons learned"},{"location":"archive/2009/2009-10-18-impromptu-zebra-a-perfect-match/","tags":["audiounit","impromptu"],"text":"I've been having so much fun using Impromptu with the Zebra audiounit lately (I just got the demo version for now). Nice sounds, very stable, clear but captivating interface, easy to control programmatically via Impromptu. Think I'm gonna buy it! Zebra is a wireless modular synthesizer . It combines numerous synthesis techniques (subtractive, additive, fm, wavetable, etc.) with a powerful modulation engine that even smoothly integrates with the built-in effects section. Unlike its analog predecessors Zebra has got an adaptive user interface that shows only what you can hear . You don't have to worry about complexity - but it's available when you need it! A demo version (AU, VST Mac & Win, RTAS Mac) is available to musicians with fastidious sound requirements: Zebra can be ordered online for only 199$ (USD)! ...","title":"Impromptu & Zebra: a perfect match!"},{"location":"archive/2009/2009-10-27-lilypond-music-notation-for-everyone/","tags":["bands","impromptu","lilypond","notation"],"text":"The inspiration for LilyPond came when two befriended musicians got annoyed with the bland and boring look of computer print-outs. Every musician prefers reading beautiful music, so couldn't we programmers solve that printing problem? LilyPond just does that: it prints music in the best traditions of classical engraving with minimum fuss. Don't waste time on tuning spacing, moving around symbols, or shaping slurs. Impress friends and colleagues with sharp sheet music! LilyPond is a free piece of software for generating nice musical sheets from specifications written on a text file. Here's a screenshot of the resulting pdf file: ... Pretty cool uh? I tried Lilypond for a little, it's pretty impressive, and the language used for creating the tablatures didn't seem too hard to master (it'd be really cool to create that on-the-fly while using Impromptu). The how-to page gives a crash course on how to create good-looking music, such as how to express notes and durations: ... You can also work directly with chords:","title":"LilyPond ... music notation for everyone"},{"location":"archive/2009/2009-10-29-impromptu-if-mod-macro/","tags":["impromptu","macro","scheme"],"text":"Hey there - this morning I checked out a nice screencast by Ben Swift and was struck by the if-mod construct he's using. It's a really useful shortcut that saves you from writing a few (possibly distracting) parenthesis, so I tried to recreate it myself. To recap.. normally with Impromptu if you want to play notes at some specific time expressed in beats with you'd have to set up a metronome first [have a look here for more info about how to use *metro*] and then check for the right beat using the modulo function. For example, something like this will play a central C every first beat of a 4/4 measure: (define *metro* (make-metro 100)) (define test (lambda (beat) (if (equal? (modulo beat 4) 0) (play dls 60 60 3)) (callback (*metro* (+ beat (* 1/2 1/4))) 'test (+ beat 1/4)))) (test (*metro* 'get-beat 4)) Another way of doing this is by using case . Same approach, but probably faster to code, as it lets you specify 'multiple beats' very easily: (define test2 (lambda (beat) (case (modulo beat 4) ((0) (play dls 60 60 3)) ((2 5/2) (play dls 67 60 1/2))) (callback (*metro* (+ beat (* 1/2 1/4))) 'test2 (+ beat 1/4)))) (test2 (*metro* 'get-beat 4)) Still quite a few parenthesis though... which, especially when playing live, might mean more chances to mess up! So when I saw Ben's video I realized that a macro usable to facilitate the creation of case/modulo expressions would be quite useful.. Here is how it can be done: (define-macro (if-mod x y args) `(for-each (lambda (step) (if (equal? (modulo beat ,x) step) ,args)) (if (list? ,y) ,y (list ,y)))) Now, by using the if-mod macro we've just created we can re-write the second example above much more concisely: (define test2-new (lambda (beat) (if-mod 4 0 (play dls 60 60 3)) (if-mod 4 '(2 5/2) (play dls 67 60 1/2)) (callback (*metro* (+ beat (* 1/2 1/4))) 'test2-new (+ beat 1/4)))) (test2-new (*metro* 'get-beat 4)) That's all! Notice also that the if-mod construct can take either a list of beats or a single one.","title":"Impromptu: If-mod macro"},{"location":"archive/2009/2009-11-04-graphics-over-code-in-impromptu/","tags":["graphics","impromptu","opengl","visualization"],"text":"Andrew Sorensen posted some code in the Impromptu mailing list showing how to add graphics (and various other things) on top of a code 'image' . As usual I regret not having a whole free day to play with this, but just by messing around a bit with some parameters it's easy to achieve some interesting effects... Here's the source code from Andrew: (gfx:start-live-video) (define canvas (gfx:make-canvas 640 480)) (define gl (gl:make-opengl)) (gl:open-opengl gl '(0 0 640 480)) ;; draw code behind a rotating cube ;; if you wanted you could now call gfx:start-movie-capture ;; and pass the gl context where canvas usually goes. (define loop-gl (lambda (beat) (let* ((code (gfx:get-code-image)) (flipped (gfx:flip-image code)) (width (car (gfx:get-image-size code))) (height (cdr (gfx:get-image-size code)))) (gl:clear gl (+ *gl:color-buffer-bit* *gl:depth-buffer-bit*)) (gl:window-pos gl 0 0 .99) (gl:draw-pixels gl width height *gl:rgba* *gl:unsigned-byte* flipped) (gl:load-identity gl) (gl:translate gl 0 0 .5) (gl:rotate gl (* beat 10) 1 1 1) (gl:color gl 1 1 1 1) (glut:wire-cube gl 0.5) (gl:flush gl) (gl:update-backing-image gl) (objc:release (+ (now) 5000) code flipped) (callback (*metro* (+ beat (* .5 1/6))) 'loop-gl (+ beat 1/6))))) (loop-gl (*metro* 'get-beat 4))8 ;; define an image to use as layer3 (define layer3 (gfx:make-image 640 480)) ;; draw paths to layer3 (define draw-on-layer3 (lambda (beat) (gfx:clear-image layer3) (dotimes (i 10) (gfx:path2image (gfx:make-circle (cosr 320 200 (/ i 100)) (sinr 240 200 (/ i 100)) 20) layer3 '() (list (/ i 5) 0 1 1))) (callback (*metro* (+ beat (* .5 1/6))) 'draw-on-layer3 (+ beat 1/6)))) (draw-on-layer3 (*metro* 'get-beat 4)) ;; draw video and layer3 transparently into the opengl bitmap ;; then render the opengl bitmap to the canvas ;; ;; You could easily replace ;; (gl:get-image-from-opengl gl) with (gfx:get-code-image) ;; if you didn't want to use any opengl (define capture-code (lambda (time) (let ((video (gfx:get-live-frame)) (opengl (gl:get-image-from-opengl gl))) (gfx:image2image video opengl .3) (gfx:image2image layer3 opengl 1) (gfx:draw-image time canvas opengl .9) (objc:release (+ time 5000) opengl video)) (callback (+ time 2000) 'capture-code (+ time 5000)))) (capture-code (now)) ;; start-movie-capture takes a canvas OR an opengl context ;; so you could call (gfx:start-movie-capture gl ... ;; as long as your gl code calls gl:update-backing-image (gfx:start-movie-capture canvas \"~/tmp/my.mov\" #t) ;(gfx:stop-movie-capture canvas)","title":"Graphics over code in Impromptu"},{"location":"archive/2009/2009-11-23-new-song-with-impromptu-kali/","tags":["impromptu","kali","livecoding","marimba"],"text":"Hey ya - new livecoding stuff from me on Vimeo . It's a song I've been working on recently, called Kali . Unfortunately I still haven't figured what the best export options for the original (1.6 Gigs) movie file are, so that I could create an export that looks less blurry on Vimeo.. but slowly I'm getting there! The sound is ok though, so hopefully you'll enjoy!","title":"New song with Impromptu: KALI"},{"location":"archive/2009/2009-12-30-free-zebra-patches/","tags":["patch","synth","zebra"],"text":"Lots of patches available for Zebra virtual instrument, you won't risk getting bored during these holidays! http://www.u-he.com/PatchLib/zebra.html [dozens of banks here..] http://rekkerd.org/patches/plug-in/zebra/ [7 banks available, I really liked the Zebra Food one]","title":"Free Zebra patches"},{"location":"archive/2010/2010-01-03-xanadu/","tags":["impromptu"],"text":"I made a new track with Impromptu, called Xanadu . Took me a little bit to build up the song base, then then I think it gets more interesting... ... If you don't care about the 'coding' side of things you can listen to a more traditional recording of the track here: Xanadu by magicrebirth","title":"Xanadu"},{"location":"archive/2010/2010-01-05-japanese-terror-in-sancasan/","tags":["electronica","japan"],"text":"Yesterday I finalized a song from last year.. it's called Japanese Terror in Sancasan . Weird title I know, but if you happen to see me live I'd be happy to tell you the story behind it (it's a bit personal). The song 's been originally made with Impromptu (the repetitive japanese sounding line in the background is randomly generated) , post-processed a bit with Audacity (added voices and so on), then passed on to my dear friend Andrea who added some nifty keyboards and re-processed the whole thing using Cakewalk . Thanks Andrea! I really love the end result. lambdaman \u00b7 Japanese Terror in Sancasan","title":"Japanese Terror in Sancasan"},{"location":"archive/2010/2010-01-10-livecoding-night-kings-college-coming-up/","tags":["event","london"],"text":"If you happen to be around London next Thursday (14th) you might be interested in joining us for an evening of livecoding ! It's free entrance, and it's going to be a dense evening of algorithmically generated music and graphics. >>> pdf version here","title":"Livecoding night @ kings college coming up"},{"location":"archive/2010/2010-02-12-video-recordings-of-the-livecoding-session-anatomy-theatre/","tags":["impromptu","livecoding","performance"],"text":"Finally I managed to shrink down to a reasonable size and upload the video recording from our last livecoding event at Kings College ; hopefully the other people will be uploading theirs too some time soon .. >>>","title":"Video recordings of the livecoding session @ anatomy theatre"},{"location":"archive/2010/2010-02-14-musical-intermezzo/","tags":["rock"],"text":"Some songs, I'll never forget. They are still giving me the shivers as they did when I was a kid. I'll let you guess the titles! Rolling down the highway, going to a show \u00b6 Rolling down the highway, going to a show Stopping on the by ways, playing rock n roll Getting robbed, getting stoned Getting beat up, broken boned Getting had, getting took I tell you folks, it's harder than it looks It's a long way to the top if you wanna rock n roll It's a long way to the top if you wanna rock n roll If you think it's easy doing one night stands Try playing in a rock n roll band It's a long way to the top if you wanna rock n roll Hotel motel, make you wanna cry Baby's on the hard sell, know the reason why Getting old, getting grey Getting ripped off, underpaid Getting sold, second hand That's how it goes playing in a band It's a long way to the top if you wanna rock n roll It's a long way to the top if you wanna rock n roll If you wanna be a star of stage and screen Look out it's rough and mean It's a long way to the top if you wanna rock n roll Gotta tell ya It's a long way to the top if you wanna rock n roll It's a long way, it's a long way, it's a long way If you're havin' trouble with your high school head \u00b6 If you're havin' trouble with your high school head He's givin' you the blues You wanna graduate but not in 'is bed Here's what you gotta do - Pick up the phone I'm always home Call me any time Just ring 36 24 36 hey I lead a life of crime Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap You got problems in your life of love You got a broken heart (She's) He's double dealin' with your best friend That's when the teardrops start - fella Pick up the phone I'm here alone Or make a social call Come right in Forget about him We'll have ourselves a ball Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap If you got a lady and you want her gone But you ain't got the guts She keeps naggin' at you night and day Enough to drive you nuts Pick up the phone Leave her alone It's time you made a stand For a fee I'm happy to be Your back door man Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap Concrete shoes, cyanide, TNT Done Dirt Cheap contracts, necties, high voltage Done Dirt Cheap dirty deeds done dirt cheap","title":"Rock intermezzo"},{"location":"archive/2010/2010-02-14-musical-intermezzo/#rolling-down-the-highway-going-to-a-show","text":"Rolling down the highway, going to a show Stopping on the by ways, playing rock n roll Getting robbed, getting stoned Getting beat up, broken boned Getting had, getting took I tell you folks, it's harder than it looks It's a long way to the top if you wanna rock n roll It's a long way to the top if you wanna rock n roll If you think it's easy doing one night stands Try playing in a rock n roll band It's a long way to the top if you wanna rock n roll Hotel motel, make you wanna cry Baby's on the hard sell, know the reason why Getting old, getting grey Getting ripped off, underpaid Getting sold, second hand That's how it goes playing in a band It's a long way to the top if you wanna rock n roll It's a long way to the top if you wanna rock n roll If you wanna be a star of stage and screen Look out it's rough and mean It's a long way to the top if you wanna rock n roll Gotta tell ya It's a long way to the top if you wanna rock n roll It's a long way, it's a long way, it's a long way","title":"Rolling down the highway, going to a show"},{"location":"archive/2010/2010-02-14-musical-intermezzo/#if-youre-havin-trouble-with-your-high-school-head","text":"If you're havin' trouble with your high school head He's givin' you the blues You wanna graduate but not in 'is bed Here's what you gotta do - Pick up the phone I'm always home Call me any time Just ring 36 24 36 hey I lead a life of crime Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap You got problems in your life of love You got a broken heart (She's) He's double dealin' with your best friend That's when the teardrops start - fella Pick up the phone I'm here alone Or make a social call Come right in Forget about him We'll have ourselves a ball Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap If you got a lady and you want her gone But you ain't got the guts She keeps naggin' at you night and day Enough to drive you nuts Pick up the phone Leave her alone It's time you made a stand For a fee I'm happy to be Your back door man Dirty Deeds Done Dirt Cheap Dirty Deeds and they're Done Dirt Cheap Concrete shoes, cyanide, TNT Done Dirt Cheap contracts, necties, high voltage Done Dirt Cheap dirty deeds done dirt cheap","title":"If you're havin' trouble with your high school head"},{"location":"archive/2010/2010-02-15-impromptu-function-to-access-wiki-docs-from-the-editor/","tags":["impromptu","scheme","url"],"text":"When you're Impromptu -ing but don't know the meaning or syntax of a function , the usual thing to do is calling (help function-name) to get some help about that function, or (help function-name #t) if you want to see also the examples associated with it. The help text gets displayed in the log view, so that you can then copy/paste what you need from there. Quite useful, but nonetheless I always find myself fighting with the log window : too small, hidden away by other canvases, or not readable anymore cause after calling the help function I've evaluated other stuff that has moved up the much needed help-text. Since a couple of months ago Impromptu has a wiki too - so I thought, it'd be nice to see a function's help in a browser window, and possibly contribute to its explanation too.. So, that's the rationale for this little script. By calling 'wiki' you can open up a web browser at the relevant Impromptu-wiki page .. as simple as that. >>> First off, we need a couple of utility functions that are not included in Impromptu by default, for better manipulating strings, lists and webpages (UPDATE 9-Nov2010: some of this symbols have been included in Improptu 2.5, so I prefixed the one below with the utils: namespace): ;;;;;;; ;; utilities ;;;;;;; ;; (utils:list-flatten '(9 9 (9 9 9 )))) = (9 9 9 9 9) ( define utils:list-flatten ( lambda ( l ) ( cond (( null? l ) ' ()) (( atom? l ) ( list l )) ( #t ( append ( utils:list-flatten ( car l )) ( utils:list-flatten ( cdr l ))))))) ;; returns a char from a string of length 1, or a list of chars from a longer string ( define utils:char ( lambda ( string_char ) ( if ( string? string_char ) ( if ( > ( string-length string_char ) 0 ) ( if ( > ( string-length string_char ) 1 ) ( string->list string_char ) ( car ( string->list string_char )))) ( print 'please 'enter 'a 'string )))) ;; matches a single character in a string, and replaces it ( define utils:string-replace ( lambda ( s match replacement ) ( let (( ll ( string->list s )) ( match1 ( utils:char match )) ( replacement1 ( utils:char replacement ))) ( if ( = ( string-length match ) 1 ) ( let (( z ( map ( lambda ( x ) ( if ( equal? x match1 ) replacement1 x )) ll ))) ( list->string ( utils:list-flatten z ))) ;z) ( print \"i can match only single characters for now\" ))))) ;; makes a string upper case ( define utils:string-capitalize ( lambda ( s ) ( string-append ( string ( char-upcase ( string-ref s 0 ))) ( substring s 1 ( string-length s ))))) ;; open-url: calls the default mac browser with a url argument ;; disclaimer: I'm not an objc programmer... found an example at ;; [http://macosx.com/forums/software-programming-web-scripting/18422-how-do-i-launch-url-using-cocoa-objective-c.html](http://macosx.com/forums/software-programming-web-scripting/18422-how-do-i-launch-url-using-cocoa-objective-c.html) ( define utils:open-url ( lambda ( urlstring ) ( let (( urlobj ( objc:call \"NSURL\" \"URLWithString:\" urlstring )) ( workspace ( objc:call \"NSWorkspace\" \"sharedWorkspace\" ))) ( objc:call workspace \"openURL:\" urlobj )))) Finally, the functions for opening the wiki page: ;;;;;;;;;; ;; wiki url caller ;; e.g. (wiki objc:from-address) => goes to http://moso.com.au/wiki/index.php?title=Objc:from-address ;;;;;;;;;; ;; wiki-escape: composes the url so that it matches the ones of the online wiki ( define wikiescape ( lambda ( funname ) ( for-each ( lambda ( x ) ( set! funname ( utils:string-replace funname ( car x ) ( cadr x )))) ' (( \"+\" \"%2B\" ) ( \"=\" \"%3D\" ) ( \"<\" \"lessthan\" ) ( \">\" \"greaterthan\" ) ( \"*\" \"%2A\" ) ( \"?\" \"%3F\" ) ( \"!\" \"%21\" ) )) ( utils:string-capitalize funname ))) ( define wiki-inner ( lambda ( funname ) ( let* (( urlbase \"[http://moso.com.au/wiki/index.php?title=](http://moso.com.au/wiki/index.php?title=)\" ) ( newname ( wikiescape funname )) ( url ( string-append urlbase newname ))) ( utils:open-url url )))) ;; macro wrapper and main function that gets called ( define-macro ( wiki name ) ` ( wiki-inner ( sexpr->string ( quote , name )))) That's it: load all of this code (or put it in a single file and load it at startup time) and you've got the wiki procedure available!","title":"Impromptu: access the Wiki docs from the editor"},{"location":"archive/2010/2010-02-18-processing-js-iprocessing-javascript-does-everything-for-you/","tags":["html5","iphone","javascript","processing"],"text":"First off - check out how cool is the little game below. It's been implemented with processing.js , a port of the famous processing library that works in your browser only through javascript (the original processing is java-based). What is processing? The Processing language was created by Ben Fry and Casey Reas . It evolved from ideas explored in the Aesthetics and Computation Group at the MIT Media Lab and was originally intended to be used in a Java run-time environment. In the Summer of 2008, John Resig ( inventor of jQuery ), ported the 2D context of Processing to Javascript for use in web pages. Mmm how about processing.js then? Processing.js is an open programming language for people who want to program images, animation, and interactions for the web without using Flash or Java applets. Processing.js uses Javascript to draw shapes and manipulate images on the HTML5 Canvas element. The code is light-weight, simple to learn and makes an ideal tool for visualizing data, creating user-interfaces and developing web-based games. Processing.js is explicitly developed for browsers that support the HTML5 element. Processing.js runs in FireFox, Safari, Opera and Chrome but will not be supported in Internet Explorer . There's more : some people in London created iProcessing , which lets you develop iPhone apps without touching objC (at least, that's what they say). Seems a bit of a revolution to me... iProcessing is an open programming framework to help people develop native iPhone applications using the Processing language. It is an integration of the Processing.js library and a Javascript application framework for iPhone. The iProcessing download consists of a set of example XCode projects that demonstrate many of the Basic Examples from the Processing web site (originally written by Casey Reas and Ben Fry unless otherwise stated) as well a number that demonstrate the use of various iPhone features such as multitouch, accelerometer, orientation, location, sound play/record, app state saving and so on .","title":"Processing.js, iProcessing: javascript does everything for you!"},{"location":"archive/2010/2010-02-24-nanoloop/","tags":["hci","iphone"],"text":"Nanoloop is a mobile music software that provides all functionality you need to create nice electronic music. With its clear, minimalistic interface it plays almost like a game while still allowing for complex musical structures as well as sheer noise. Nanoloop for iPhone combines sequencer , synthesizer and sampler in one package. Features include: - Six channels, each can be synth or sampler - Fast and easy to use stepsequencer - Synthesizer with envelope, filter, LFO and other parameters - Sample external audio or nanoloop's own sound output - Song editor with loop function - Save function - Works on 1st gen iPod touch and 2.2 software - Send and receive projects via e-mail, using the iPhone's / iPod's e-mail program I found out about it via creativeApplications.net , and I loved the simplicity of the interface straightaway!!","title":"Nanoloop"},{"location":"archive/2010/2010-03-05-bbc-article-on-interactive-art-at-goldsmith-university-london/","tags":["article","bbc","goldsmith","london"],"text":"An interesting BBC article about the interactive art being produced by Goldsmiths students. \"That's what makes science great, and technology great and art great,\" he said \"It's about playing with ideas. \"You try a few things out and see what happens, then try more and more and you come up with something that is genius,\" he said. Only by building it, seeing and shaping it, can they truly understand. Something any and every maker can identify with.","title":"BBC article on interactive art at Goldsmith University (London)"},{"location":"archive/2010/2010-03-09-japanese-figurative-paintings/","tags":["art","japan","painting"],"text":"I went to the National Museum of art in Osaka the other day, and saw a lot of inspiring stuff. The exhibition that was on was titled \"Garden of Painting\u2014Japanese Art of the 00s\": To commemorate the fifth anniversary of the National Museum of Art, Osaka's relocation from Expo Park to Nakanoshima, in the heart of Osaka, we are pleased to present a special exhibition titled \"Garden of Painting\u2014Japanese Art of the 00s.\" In this event, we focus on new figurative painting from the last decade to showcase the vibrant activities of a younger generation of Japanese artists. In this exhibition, we present some 200 works by 28 artists, including recent and new works, throughout the museum's exhibition spaces in the second- and third-floor basements. Among these are the unforgettable O Jun with his witty portraits and iconography; Kobayashi Takanobu, who depicts landscapes and people shrouded in a distinctive kind of light; artists from the preceding generation such as Nara Yoshitomo, who is known for his pictures of young girls with incisive looks; up-and-coming artists like Goto Yasuka, Sakamoto Natsuko, and Atsuchi Tomoko, who were born in the 1980s; and Kusama Yayoi, who has in recent years been exploring new frontiers in painting through her use of line drawings. Here's a list of the things I liked the most: Goto Yasuka , 'yosegaki' Nara Yoshitomo , 'the little judge', 'agent orange', 'after the acid rain' Hanazawa Takeo , 'winter garden', 'mikrokozmosz' Ikeda Mitsuhiro , 'untitled' Kato Mika , 'canaria', 'cloud' Kobayashi Takanobu , 'forest', 'sunbather 8', 'pillow' Ozawa Sakae , 'Zauber/magic', 'the secret of the world tastes like honey', 'i always wanted to cry', 'the world becomes dream, the dream becomes world' - Kusama Yayoi Makishima Takeshi , 'dragonfly', 'replay', 'in motion', 'helios' Sugito Hiroshi , 'quadII' Machida Kumi , 'gentle people', 'rocking horse' Aida Makoto , 'picture of waterfall' Hoki Nobuya , 'untitled' Sakamoto Natsuko , 'tiles', 'tiles, shower'","title":"Japanese figurative paintings"},{"location":"archive/2010/2010-03-29-algorithms-are-thoughts-chainsaws-are-tools/","tags":["impromptu","movie"],"text":"A short movie about livecoding , Andrew Sorensen (creator of Impromptu ), TOPLAP and other related stuff. If you're not familiar with this stuff, I'd say it's the most pleasant introduction to it available at the moment! Thanks Stepher Ramsay for doing this!","title":"Algorithms are Thoughts, Chainsaws are Tools"},{"location":"archive/2010/2010-04-02-finally-some-more-livecoding/","tags":["impromptu","video"],"text":"I've been experimenting a bit with picking random notes from a scale using various voices simultaneously, so to create interesting sounds textures... and what came out is maybe a bit too random at the beginning, but getting more interesting towards the end imho ... Oh yeah, the song is called 'My Misty Morning' .","title":"Finally some more livecoding"},{"location":"archive/2010/2010-06-12-the-rebirth-of-rebirth/","tags":["audio","iphone","propellerhead","synth"],"text":"ReBirth faithfully emulates dance music's three backbone devices: The Roland TB-303 Bass synth and the Roland TR-808 and 909 drum machines. Combine these with FX units, fully featured pattern sequencers and a quick-acting, scalable iPhone interface and you'll soon be making techno on the train, trance on the tram or beats on the bus. Rebirth is one of the reasons that made me switch to macs, more than ten years ago. It was an incredibly user-friendly piece of software with which you could easily create all sorts of electronic tunes, from the most acid-sounding techno lines to drum and base tracks. It was still the age of OS9, iMacs and the colorful iBooks.. then with the advent of osX Rebirth wasn't supported anymore, and it turned into a museum . So now seeing it reborn into an iPhone app is just amazing. It's available on the Apple Store for 3.99 pounds (link). I bought it and had a go: the sound is as great as the original, but unfortunately controlling the interface is not as much fun. The iPhone is just too small in my opinion... but I guess that if you could run it on the iPad that would change everything (I don't have one, but I suppose it just should scale up as needed). *********** A couple of related audio&iPhone links: - GravSynth : an analog synthesizer, fun to use. - MobileSynth : a google project providing foundational open source iPhone code for building synthesizers.","title":"The Rebirth of Rebirth!"},{"location":"archive/2010/2010-06-13-plork-spring-2010-concert/","tags":["laptop","live","princeton"],"text":"I just watched online a number of very inspiring performances from the the Princeton Laptop Orchestra ( PLOrk ), as part of the their recent Spring Concert . I usually do livecoding on my own, so I'm really impressed by the results an enseble of livecoders can get! Some of the performances I liked: N. 5. Middle Passage, by Anne Hege: [ video ] N. 4. alskdjalskdjalskdj, by Konrad Kaczmarek: [ video ] N. 6. LOLC, by Akito Van Troyer and Jason Freeman (more info about the livecoding environment here ): [ video ] ********* You'll find many more cool audio&computing things by checking out the Princeton Sound Lab website [ people | research | listen | learning | software | publications ] !","title":"PLOrk @=> Spring 2010 Concert"},{"location":"archive/2010/2010-06-17-ozrics-back-on-the-road/","tags":["gigs","london","ozrics","psychedelic"],"text":"Good news, mythical Ozric Tentacles [ official website ] are going to have a number of gigs in the UK in the coming fall. All the dates are available at allgigs.co.uk . They'll play in London on Thu 28th Oct 2010 at the Islington Academy, it's only 25 quid , get in touch if you want to join me! Ozric Tentacles (commonly known as the Ozrics) are an instrumental rock band from Somerset, England, whose music can loosely be described as psychedelic or space rock. Formed in 1984, the band has released 28 albums as of 2009, and become a cottage industry selling over a million albums worldwide despite never having major label backing. [ wikipedia ] This is 'Saucers', for the 'Strangeitude' album: I saw them live a coupe of times already, never got disappointed with the performance..","title":"Ozrics back on the road!"},{"location":"archive/2010/2010-06-19-aviary-roc-online-free-music-sequencer/","tags":["online","sequencer"],"text":"Aviary's ROC Music Creator is a free online music sequencing tool written using Adobe's AIR framework. I just tried it, not really what I need right now but I can't say it's not a good product: easy to use (you can make music loops and ringtones pretty fast), attractive interface, nice sounds (more than 50 instruments including pianos, guitars, percussions), export capabilities (download mp3s with one click), voice recording, sharing functionalities to work with others. Aviary is a New York based company that is creating a number of different products for enhancing people's creativity . Good news is, all of them are free! The online application currently available are: In Beta release: Phoenix , our layer-based image editor Peacock , our visual laboratory for creating amazing effects and visualizations Toucan , our color pallette coordinator For Alpha testing (only available to members of the Blue plan):- Raven , our vector editor - Talon , our Firefox extension that allows users to perform screen capturing.","title":"Aviary' ROC: online free music sequencer"},{"location":"archive/2010/2010-07-13-bernsteins-mass-at-royal-festical-hall/","tags":["bernstein","classical","london","mass"],"text":"The other day I went to a concert at the Southbank Centre in London, as part of the Leonard Bernstein season . Its the Mass by Leonard Bernstein . A bit hard to follow, maybe because of the mix of latin and english in the lyrics, but the musics and the theatrical bits were quite entertaining. (wikipedia link ): MASS (formally, \"MASS: A Theatre Piece for Singers, Players, and Dancers\") is a musical theatre work composed by Leonard Bernstein. Commissioned by Jacqueline Kennedy , it premiered on September 8, 1971, conducted by Maurice Peress.[1] The performance was part of the opening of the John F. Kennedy Center for the Performing Arts in Washington, D.C.[2] Mass premiered in Europe in 1973, with John Mauceri conducting the Yale Symphony Orchestra in Vienna.[3] Originally, Bernstein had intended to compose a traditional Mass, but instead decided on a more innovative form . The work is based on the Tridentine Mass of the Roman Catholic Church. Although the liturgical passages are sung in Latin, Mass also includes additional texts in English written by Bernstein, Broadway composer Stephen Schwartz, and Paul Simon (who wrote the first quatrain of the trope \"Half of the People\"). The work is intended to be staged theatrically , but it has also been performed in a standard concert setting. Reviews: [ Reuters ] [ Guardian ] [ Independent ]","title":"Bernstein's Mass at Royal Festival Hall"},{"location":"archive/2010/2010-08-09-listen-to-the-rainforest-at-kew-gardens/","tags":["gardens","installation","london","nature","sound","tropical"],"text":"If you happen to be going to London's Kew Gardens , make sure you don't miss this nice sound installation by Chris Watson . The installation is on till September 5th and it's called Whispering in the Leaves : Whispering in the Leaves features two sound pieces \u2013 Dawn and Dusk \u2013 composed by Chris from memory using his extensive archive of on-location recordings in Central and South American rainforests . Designed specifically for the Palm House, Whispering in the Leaves is the audio equivalent of 3D cinema. Visitors will be immersed in a dynamic, spatial soundscape of primate calls and birdsong , backed with a shimmering wall of insect sounds. Some of the species heard are currently unknown to humans. Visitors will experience the heard but never seen. Diffused through 80 speakers , the two compositions will be transmitted at hourly intervals throughout the day - Dawn in the morning and Dusk in the afternoon. Each lasts for 15-20 minute durations \u2013 the approximate time it takes for the transitions between darkness and daylight in the dense tropical vegetation. The website makes available some of the nature recordings too. ...","title":"Listen to the RainForest at Kew Gardens"},{"location":"archive/2010/2010-08-10-learning-resources-about-scheme/","tags":["books","impromptu","learning","scheme"],"text":"So you've decided to know everything about scheme and rock the world using fast-paced programming environments like Impromptu . Well, I confess I did think that on several occasions, but still I haven't made it even half way through the schemer pilgmim's path . But I've collected quite a few useful resources in the process, and those I can certainly share! So in what follows I've put together a list of learning resources about Scheme that I found useful.. First off, two links that might be useful in all situations: Little Scheme , an online interpreter that you can use for testing things out while you're on holidays Schemers.org , semi-official website containing news and lots of links to other resources Now, why don't we start with the definition offered by the self-regulating wikipedia collective intelligence? Here we go: Scheme is one of the two main dialects of the programming language Lisp . Unlike Common Lisp, the other main dialect, Scheme follows a minimalist design philosophy specifying a small standard core with powerful tools for language extension. Its compactness and elegance have made it popular with educators, language designers, programmers, implementors, and hobbyists , and this diverse appeal is seen as both a strength and, because of the diversity of its constituencies and the wide divergence between implementations, one of its weaknesses If this blurb hasn't made you proud of learning such a slick language, you'll surely find more interesting ideas in what follows. I divided up the list in two sections, generic learning materials about scheme, and tutorials about specific topics (for now, only macros are included). ---------------------------------- 1. Learning Resources About Scheme: \u00b6 Scheme for Common Lispers , article The Scheme dialect of Lisp was created in 1975 by Guy Steele and Gerry Sussman to explore ideas in programming-language semantics. They showed that a powerful language can be made ``not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary''. Scheme pioneered lexical scope in Lisp, first-class continuations, and tail recursion, and more recently added an advanced macro system. It's the best-known Lisp dialect after Common Lisp (which it influenced). This note summarizes the differences from CL that might slow down a CL programmer trying to read a Scheme program ; people without a CL background, or wanting to write programs of their own, should see the references. the Schematics Scheme Cookbook The Schematics Scheme Cookbook is a collaborative effort to produce documentation and recipes for using Scheme for common tasks . See the BookIntroduction for more information on the Cookbook's goals, and the important ContributorAgreement statement. Harvey, Wright, Simply Scheme: Introducing Computer Science , 1999 MIT press [ a classic ] Symbolic programming is one aspect of the reason why we like to teach computer science using Scheme instead of a more traditional language. More generally, Lisp (and therefore Scheme) was designed to support what we've called the radical view of computer science. In this view, computer science is about tools for expressing ideas . Symbolic programming allows the computer to express ideas; other aspects of Lisp's design help the programmer express ideas conveniently. Sometimes that goal comes in conflict with the conservative computer scientist's goal of protection against errors. Felleisen, Findler, Flatt, Krishnamurthi, How to Design Programs An Introduction to Computing and Programming , MIT 2001 [..] programming is more than just a vocational skill. Indeed, good programming is a fun activity, a creative outlet, and a way to express abstract ideas in a tangible form. And designing programs teaches a variety of skills that are important in all kinds of professions: critical reading, analytical thinking, creative synthesis, and attention to detail. We therefore believe that the study of program design deserves the same central role in general education as mathematics and English. Or, put more succinctly, everyone should learn how to design programs . On one hand, program design teaches the same analytical skills as mathematics. But, unlike mathematics, working with programs is an active approach to learning . Interacting with software provides immediate feedback and thus leads to exploration, experimentation, and self-evaluation. Furthermore, designing programs produces useful and fun things, which vastly increases the sense of accomplishment when compared to drill exercises in mathematics. On the other hand, program design teaches the same analytical reading and writing skills as English. Even the smallest programming tasks are formulated as word problems. Without critical reading skills, a student cannot design programs that match the specification. Conversely, good program design methods force a student to articulate thoughts about programs in proper English. Dybvig, The Scheme Programming Language , 2003MIT press This book is intended to provide an introduction to the Scheme programming language but not an introduction to programming in general . The reader is expected to have had some experience programming and to be familiar with terms commonly associated with computers and programming languages. The author recommends that readers unfamiliar with Scheme or Lisp also read The Little Schemer [ see below ]to become familiar with the concepts of list processing and recursion. Readers new to programming should begin with an introductory text on programming. Nils M Holm, \" Sketchy LISP \" [you can download the book here Update 08/12: this book has become 'Sketchy Scheme' and is now for-sale here ] Sketchy LISP is a step-by-step introduction to functional programming in Scheme. It covers various aspects of the language including data types, conditional evaluation, list processing, lexical scoping, closures, recursion, dynamic typing, etc. By means of numerous examples of varying complexity, it takes the reader on an entertaining and informative tour through the language. The Scheme language achieves what only few languages have managed before: to bring fun back to programming . Its simple syntax, clean semantics, and powerful functions open the door to a fresh perspective on program design. Programming in Scheme is fun, and this book is an attempt to share some of that fun. Friedman and Felleisen, The Little Schemer , 1996 MIT press The goal of this book is to teach the reader to think recursively . Our first task, therefore, is to decide which language to use to communicate this concept. There are three obvious choices: a natural language, such as English; formal mathematics; or a programming language. Natural languages are ambiguous, imprecise, and sometimes awkwardly verbose. These are all virtues for general communication, but something of a drawback for communicating concisely as precise a concept as the power of recursion. The language of mathematics is the opposite of natural language: it can express powerful formal ideas with only a few symbols. We could, for example, describe the entire technical content of this book in less than a page of mathematics, but the reader who understands that page has little need for this book. For most people, formal mathematics is not very intuitive. The marriage of technology and mathematics presents us with a third, almost ideal choice: a programming language. Programming languages are perhaps the best way to convey the concept of recursion. They share with mathematics the ability to give a formal meaning to a set of symbols. But unlike mathematics, programming languages can be directly experienced---you can take the programs in this book and try them, observe their behavior, modify them, and experience the effect of your modifications. The Weiner Lectures Archives [various videos, but not complete lectures unfortunately] The goal of this project is to make knowledge of computer science easily available not only to the students at Berkeley, but also to the entire community. For several years, faculty members have been videotaping lectures in CS large lower division courses, mainly as an aid to students with time conflicts that prevent them from attending lectures. By hosting an archive storing all CS lectures that were recorded , we hope the computing knowledge that has been gathered can be easily shared. As a teaching aid, a 'greatest hits' lecture will also be compiled for each course covering all major topics addressed in the corresponding class. The best parts of many different past lectures will be linked together and presented along with slides to make this greatest hits lecture. This lecture should represent the best teaching abilities in the lower division CS lectures and should be a valuable resource in the computer community for basic CS knowledge. Thanks to the generous donation of Larry Weiner this online site should become a permanent resource. ---------------------- 2. Specific topics: \u00b6 On Macros and metaprogramming: \u00b6 The art of metaprogramming, Part 1: Introduction to metaprogramming , IBM developer works Summary: One of the most under-used programming techniques is writing programs that generate programs or program parts . Learn why metaprogramming is necessary and look at some of the components of metaprogramming (textual macro languages, specialized code generators). See how to build a code generator and get a closer look at language-sensitive macro programming in Scheme. Lisp Macros -- How to Define Entirely New Languages in Lisp This is a very interesting lesson if you want to deeply understand Lisp, and some very deep things about programming, but it's also entirely optional; We suggest that you do through it, but not worry too much about understanding it in detail. If you get very deeply into programming, you'll find that Lisp macros are an amazing tool, but they are also somewhat mind-bending , and used rather rarely in simple programming. So, feel free to skip this lesson, or at least, if you do study it, let it flow over you, and maybe come back to it later on if you find yourself wanting to know more about some of the deep and subtle reaches of Lisp programming. Scheme FAQ Macros , on schemewiki.org Sources for learning about Scheme Macros: define-syntax and syntax-rules , a thread on StackOverflow A scheme syntax rules primer , an interesting blog post ---------------------- That's all for now... I'll be adding more stuff as I run into it!","title":"Learning resources about Scheme"},{"location":"archive/2010/2010-08-10-learning-resources-about-scheme/#1-learning-resources-about-scheme","text":"Scheme for Common Lispers , article The Scheme dialect of Lisp was created in 1975 by Guy Steele and Gerry Sussman to explore ideas in programming-language semantics. They showed that a powerful language can be made ``not by piling feature on top of feature, but by removing the weaknesses and restrictions that make additional features appear necessary''. Scheme pioneered lexical scope in Lisp, first-class continuations, and tail recursion, and more recently added an advanced macro system. It's the best-known Lisp dialect after Common Lisp (which it influenced). This note summarizes the differences from CL that might slow down a CL programmer trying to read a Scheme program ; people without a CL background, or wanting to write programs of their own, should see the references. the Schematics Scheme Cookbook The Schematics Scheme Cookbook is a collaborative effort to produce documentation and recipes for using Scheme for common tasks . See the BookIntroduction for more information on the Cookbook's goals, and the important ContributorAgreement statement. Harvey, Wright, Simply Scheme: Introducing Computer Science , 1999 MIT press [ a classic ] Symbolic programming is one aspect of the reason why we like to teach computer science using Scheme instead of a more traditional language. More generally, Lisp (and therefore Scheme) was designed to support what we've called the radical view of computer science. In this view, computer science is about tools for expressing ideas . Symbolic programming allows the computer to express ideas; other aspects of Lisp's design help the programmer express ideas conveniently. Sometimes that goal comes in conflict with the conservative computer scientist's goal of protection against errors. Felleisen, Findler, Flatt, Krishnamurthi, How to Design Programs An Introduction to Computing and Programming , MIT 2001 [..] programming is more than just a vocational skill. Indeed, good programming is a fun activity, a creative outlet, and a way to express abstract ideas in a tangible form. And designing programs teaches a variety of skills that are important in all kinds of professions: critical reading, analytical thinking, creative synthesis, and attention to detail. We therefore believe that the study of program design deserves the same central role in general education as mathematics and English. Or, put more succinctly, everyone should learn how to design programs . On one hand, program design teaches the same analytical skills as mathematics. But, unlike mathematics, working with programs is an active approach to learning . Interacting with software provides immediate feedback and thus leads to exploration, experimentation, and self-evaluation. Furthermore, designing programs produces useful and fun things, which vastly increases the sense of accomplishment when compared to drill exercises in mathematics. On the other hand, program design teaches the same analytical reading and writing skills as English. Even the smallest programming tasks are formulated as word problems. Without critical reading skills, a student cannot design programs that match the specification. Conversely, good program design methods force a student to articulate thoughts about programs in proper English. Dybvig, The Scheme Programming Language , 2003MIT press This book is intended to provide an introduction to the Scheme programming language but not an introduction to programming in general . The reader is expected to have had some experience programming and to be familiar with terms commonly associated with computers and programming languages. The author recommends that readers unfamiliar with Scheme or Lisp also read The Little Schemer [ see below ]to become familiar with the concepts of list processing and recursion. Readers new to programming should begin with an introductory text on programming. Nils M Holm, \" Sketchy LISP \" [you can download the book here Update 08/12: this book has become 'Sketchy Scheme' and is now for-sale here ] Sketchy LISP is a step-by-step introduction to functional programming in Scheme. It covers various aspects of the language including data types, conditional evaluation, list processing, lexical scoping, closures, recursion, dynamic typing, etc. By means of numerous examples of varying complexity, it takes the reader on an entertaining and informative tour through the language. The Scheme language achieves what only few languages have managed before: to bring fun back to programming . Its simple syntax, clean semantics, and powerful functions open the door to a fresh perspective on program design. Programming in Scheme is fun, and this book is an attempt to share some of that fun. Friedman and Felleisen, The Little Schemer , 1996 MIT press The goal of this book is to teach the reader to think recursively . Our first task, therefore, is to decide which language to use to communicate this concept. There are three obvious choices: a natural language, such as English; formal mathematics; or a programming language. Natural languages are ambiguous, imprecise, and sometimes awkwardly verbose. These are all virtues for general communication, but something of a drawback for communicating concisely as precise a concept as the power of recursion. The language of mathematics is the opposite of natural language: it can express powerful formal ideas with only a few symbols. We could, for example, describe the entire technical content of this book in less than a page of mathematics, but the reader who understands that page has little need for this book. For most people, formal mathematics is not very intuitive. The marriage of technology and mathematics presents us with a third, almost ideal choice: a programming language. Programming languages are perhaps the best way to convey the concept of recursion. They share with mathematics the ability to give a formal meaning to a set of symbols. But unlike mathematics, programming languages can be directly experienced---you can take the programs in this book and try them, observe their behavior, modify them, and experience the effect of your modifications. The Weiner Lectures Archives [various videos, but not complete lectures unfortunately] The goal of this project is to make knowledge of computer science easily available not only to the students at Berkeley, but also to the entire community. For several years, faculty members have been videotaping lectures in CS large lower division courses, mainly as an aid to students with time conflicts that prevent them from attending lectures. By hosting an archive storing all CS lectures that were recorded , we hope the computing knowledge that has been gathered can be easily shared. As a teaching aid, a 'greatest hits' lecture will also be compiled for each course covering all major topics addressed in the corresponding class. The best parts of many different past lectures will be linked together and presented along with slides to make this greatest hits lecture. This lecture should represent the best teaching abilities in the lower division CS lectures and should be a valuable resource in the computer community for basic CS knowledge. Thanks to the generous donation of Larry Weiner this online site should become a permanent resource. ----------------------","title":"1. Learning Resources About Scheme:"},{"location":"archive/2010/2010-08-10-learning-resources-about-scheme/#2-specific-topics","text":"","title":"2. Specific topics:"},{"location":"archive/2010/2010-08-10-learning-resources-about-scheme/#on-macros-and-metaprogramming","text":"The art of metaprogramming, Part 1: Introduction to metaprogramming , IBM developer works Summary: One of the most under-used programming techniques is writing programs that generate programs or program parts . Learn why metaprogramming is necessary and look at some of the components of metaprogramming (textual macro languages, specialized code generators). See how to build a code generator and get a closer look at language-sensitive macro programming in Scheme. Lisp Macros -- How to Define Entirely New Languages in Lisp This is a very interesting lesson if you want to deeply understand Lisp, and some very deep things about programming, but it's also entirely optional; We suggest that you do through it, but not worry too much about understanding it in detail. If you get very deeply into programming, you'll find that Lisp macros are an amazing tool, but they are also somewhat mind-bending , and used rather rarely in simple programming. So, feel free to skip this lesson, or at least, if you do study it, let it flow over you, and maybe come back to it later on if you find yourself wanting to know more about some of the deep and subtle reaches of Lisp programming. Scheme FAQ Macros , on schemewiki.org Sources for learning about Scheme Macros: define-syntax and syntax-rules , a thread on StackOverflow A scheme syntax rules primer , an interesting blog post ---------------------- That's all for now... I'll be adding more stuff as I run into it!","title":"On Macros and metaprogramming:"},{"location":"archive/2010/2010-09-01-little-brilliant-music-player-pico-play/","tags":["mp3","player"],"text":"The purpose of Pico Play is very simple: don't get in the way. You want to listen to music without having to load any heavy application (iTunes included) - but still being able to use all the songs in your iTunes playlist... this is the piece of software you need. And it's free !","title":"Little brilliant music player: Pico Play"},{"location":"archive/2010/2010-09-08-ars-electronica-2010/","tags":["austria","digitalart","linz"],"text":"I spent a couple of days in Linz, Austria, visiting for the first time the Ars Electronica centre and the related festival which is happening these days. It's an impressive event, lots and lots of things to see, spanning from the latest technologies used in scientific research to the most visionary art installations. The city and people of Linz (and Austria, more generally) are definitely doing a wonderful job in keeping this up, and especially in making this so accessible also to non-experts! The video summarizes a bit the things I've seen (but trust me, there's LOTS more!) including: Ars Electronica Center: \u00b6 FabLab , BioLab , BrainLab , RoboLab , Raise Your Voice , Funky Pixels Ars Electronica Festival: \u00b6 Hylozoic Grove [Philip Beesley], the homeless robot [Electric Circus], Porcelain recycling, the Windowfarms project , Telenoid [Hiroshi Ishiguro], Ocean of Light: Surface [Anthony Rowe, Gareth Bushell, Chris Bennewith, Liam Birtles, Ollie Bown], Earth [Finnbogi Petursson], Lighting Choreographer [Minoru Fujimoto], Fuckhead , Sonic Architecture: natural reverberation space, Cycloid-E [Michel D\u00e9costerd, Andr\u00e9 D\u00e9costerd], My husband and me, me and my wife [Nico Ferrando], Braun Tube Jazz Band [Ei Wada], Dies Irae - Remembering EB 180 You can find many more pictures on the Ars Electronica flickr page .","title":"Ars Electronica 2010"},{"location":"archive/2010/2010-09-08-ars-electronica-2010/#ars-electronica-center","text":"FabLab , BioLab , BrainLab , RoboLab , Raise Your Voice , Funky Pixels","title":"Ars Electronica Center:"},{"location":"archive/2010/2010-09-08-ars-electronica-2010/#ars-electronica-festival","text":"Hylozoic Grove [Philip Beesley], the homeless robot [Electric Circus], Porcelain recycling, the Windowfarms project , Telenoid [Hiroshi Ishiguro], Ocean of Light: Surface [Anthony Rowe, Gareth Bushell, Chris Bennewith, Liam Birtles, Ollie Bown], Earth [Finnbogi Petursson], Lighting Choreographer [Minoru Fujimoto], Fuckhead , Sonic Architecture: natural reverberation space, Cycloid-E [Michel D\u00e9costerd, Andr\u00e9 D\u00e9costerd], My husband and me, me and my wife [Nico Ferrando], Braun Tube Jazz Band [Ei Wada], Dies Irae - Remembering EB 180 You can find many more pictures on the Ars Electronica flickr page .","title":"Ars Electronica Festival:"},{"location":"archive/2010/2010-09-15-the-bad-plus-iron-man/","tags":["aphextwin","blacksabbath","jazz"],"text":"The Bad Plus - each time I listen to them I can't avoid thinking they're geniuses! Coming to London for the Jazz festival next november... UPDATE 22/11/10: I went to the London gig and it was awesome - here's an excerpt:","title":"The Bad Plus - Iron Man"},{"location":"archive/2010/2010-09-16-musorg-tons-of-classical-music-for-free/","tags":["classical","free","sheetmusic"],"text":"I found out about this via o'reilly radar's blog .. Musopen is an online music library of copyright free (public domain) music . We want to give the world access to music without the legal hassles so common today. There is a great deal of music that has expired copyrights, but almost no recordings of this music is in the public domain. We aim to record or obtain recordings that have no copyrights so that our visitors may listen, re-use, or in any way enjoy music. Put simply, our mission is to set music free. The amount of music available is not too bad (and constantly improving): Also, they have a growing collection of sheet music, eg:","title":"Musorg : tons of classical music for free"},{"location":"archive/2010/2010-10-13-impromptu-2-5/","tags":["impromptu"],"text":"Good news for livecoders: a new version of Impromptu is available (direct link to the 2.5 dmg package) . Apart from various bug fixes, it looks like as if the major development is the ICR ( impromptu compiler runtime ), a new set of scheme functions that facilitate the creation of faster bytecode, so that computationally-intensive tasks such as real time audio processing or open-gl can perform more efficiently. The new compiler is a far more robust and serious attempt at providing low level, but completely dynamic programming support within the Impromptu ecosystem. It is designed for situations which require low-level systems style programming. Two primary examples are audio signal processing and opengl programming - both of which require the production of highly efficient code. While attempting to achieve runtime efficiency the ICR also tries to maintain Impromptu's love of all things dynamic and is designed to coexist with the rest of Impromptu's infrastructure (Scheme, Objective-C, AudioUnits etc..). The new compiler seems to be introducing some pretty foundamental improvements: It is important to state from the outset that the new Impromptu compiler is NOT a scheme compiler. It is really its own language . This language looks like scheme (sexpr's and alike) but is in many ways semantically closer to C (a nice functional version of C :-). This is because the ICR is designed for purposes that are not suitable for the standard scheme interpreted environment. Low level tasks that require efficient processing - such as audio signal processing, graphics programming, or general numerical programming. Unlike Scheme the Impromptu compiler is statically typed. You may not always see the static typing but it is always there in the background. The reason that you won't always see the typing is that the compiler includes a type-inferencer that attempts to guess at your types based on static analysis of your code. Sometimes this works great, sometimes it doesn't. When things fail, as they surely will, you are able to explicitly specify types to the compiler. A big thanks to Andrew Sorensen for keeping up (and free) this great work!","title":"Impromptu 2.5 released"},{"location":"archive/2010/2010-10-28-jeff-beck-live-at-the-royal-albert-hall/","tags":["beck","blues","guitar","live","london","rock"],"text":"Quite an amazing evening with Beck rocking the RAH out the other night; the man is well over 60 (born 24 June 1944) but still performs with great confidence and inventiveness. I loved every minute of it!","title":"Jeff Beck live at the Royal Albert Hall"},{"location":"archive/2010/2010-10-29-ozric-tentacles-live-islington-academy-london/","tags":["electronica","event","london","ozrics","psychedelic","space-rock"],"text":"The lineup featured Ed Wynne (guitar, synths), Ed's wife Brandi Wynne (bass, keyboards), Silas Wynne (synths, keyboards - Ed's son) and Oliver Seagle (drums, percussion). Can't say I haven't missed the old line up , with \"Jumping Jon\" Egan, who used to dance around the stage in a trance-like manner while playing a variety of flutes... but still I had quite a bit of fun listening to this weird psychedelic family belting out spacey vibes. Even more cause they included several old Ozrics classics which I really enjoyed! Here's an excerpt I've taken with my phone:","title":"Ozric Tentacles live @ Islington Academy, London"},{"location":"archive/2010/2010-11-08-scheme-and-lisp/","tags":["code","comparison","lisp","programming-2","scheme"],"text":"If you're coming from Lisp, and then start using Scheme (or the other way around) there are a few small differences between the two languages that it's useful to always keep in mind. I tried to switch languages a number of times, but inevitably I found myself once again wondering: how do you say progn in Scheme ? Scheme VS Lisp: key differences \u00b6 So, since I recently found online a succinct table that sums up the differences, I thought I'd pass it on to posterity here too. By the way, on the same site the authors report of a small scheme library ( initdr.scm ) that implements a few very common Lisp functions. Including [dotimes dolist intersection, union set-difference copy-list subset every some copy-tree subst sublis nconc nreverse]... Quite useful too! Update 28/11/10: \u00b6 I realized that most of these lisp functions are already available in Impromptu, under the cl: namespace (check out the common-lisp library functions section on the wiki). Below there are just a couple of additions to that, based on the initdr.scm library I was mentioning.. apologies for the confusion! ;;;;;;;;;;;;;;;; ;;; LISP ADDITIONS ;; the rest of this is in the cl: impromptu library ;;;;;;;;;;;;;;;; ( define cl:first car ) ( define cl:rest cdr ) ( define cl:count length ) ;; reverse of cons: (cons 'b '(a)) ( define cl:l-put ( lambda ( obj lst ) ( reverse ( cons obj ( reverse lst ))))) ;; dont know why but I like it reversed.. ( define cl:nth ( lambda ( x lst ) ( list-ref lst x ))) ( define ( 1 + n ) ( + n 1 )) ( define ( 1 - n ) ( \\ - n 1 )) ;; (subst 9 7 '(5 (5 6 7(6 7)))) => (5 (5 6 9 (6 9))) ( define ( cl:subst new old tree ) ( if ( pair? tree ) ( let (( left ( subst new old ( car tree ))) ( right ( subst new old ( cdr tree )))) ( if ( and ( eq? left ( car tree )) ( eq? right ( cdr tree ))) tree ( cons left right ))) ( if ( eqv? old tree ) new tree ))) ;; (sublis '((6 . 9) (7 . 10)) '(5 (5 6 7 (6 7))))) => (5 (5 9 10 (9 10))) ( define ( cl:sublis alist tree ) ( if ( pair? tree ) ( let (( left ( sublis alist ( car tree ))) ( right ( sublis alist ( cdr tree )))) ( if ( and ( eq? left ( car tree )) ( eq? right ( cdr tree ))) tree ( cons left right ))) ( let (( new ( assv tree alist ))) ( if new ( cdr new ) tree ) ) ) ) ;; (copy-tree '(5 (5 6 7(6 7)))) ( define ( cl:copy-tree x ) ( if ( pair? x ) ( cons ( copy-tree ( car x )) ( copy-tree ( cdr x ))) x )) ; Convert a floating-point number to a string of sign and at most 4 characters. ; Rounds the number so that 1.999 will come out as 2.00 , very small as 0.0 . ; numstring is written assuming that num is not too large or too small, ; i.e. num must be printable in 4 digits. ( define ( cl:numstring num ) ( let \\ * (( numc ( abs num )) ( sign ( if ( < num 0 ) -1 1 )) ( exponent 0 )) ( if ( < numc 1.0 e-6 ) \"0.0\" ( begin ( if ( < numc 1.0 ) ( begin ( while ( < numc 100 ) ( set! numc ( \\ * numc 10 )) ( set! exponent ( 1 - exponent ))) ( set! numc ( \\ * ( round numc ) ( expt 10 exponent ))) ) ( set! numc ( \\ * numc 1.0001 ))) ( if ( < sign 0 ) ( string-append \"-\" ( substring ( number->string numc ) 0 ( min 4 ( string-length ( number->string numc ))))) ( substring ( number->string numc ) 0 ( min 4 ( string-length ( number->string numc ))))) ) ) )) ;(list-flatten '(9 9 (9 9 9 )))) = (9 9 9 9 9) ( define cl:list-flatten ( lambda ( l ) ( cond (( null? l ) ' ()) (( atom? l ) ( list l )) ( #t ( append ( cl:list-flatten ( car l )) ( cl:list-flatten ( cdr l )))))))","title":"Scheme and Lisp"},{"location":"archive/2010/2010-11-08-scheme-and-lisp/#scheme-vs-lisp-key-differences","text":"So, since I recently found online a succinct table that sums up the differences, I thought I'd pass it on to posterity here too. By the way, on the same site the authors report of a small scheme library ( initdr.scm ) that implements a few very common Lisp functions. Including [dotimes dolist intersection, union set-difference copy-list subset every some copy-tree subst sublis nconc nreverse]... Quite useful too!","title":"Scheme VS Lisp: key differences"},{"location":"archive/2010/2010-11-08-scheme-and-lisp/#update-281110","text":"I realized that most of these lisp functions are already available in Impromptu, under the cl: namespace (check out the common-lisp library functions section on the wiki). Below there are just a couple of additions to that, based on the initdr.scm library I was mentioning.. apologies for the confusion! ;;;;;;;;;;;;;;;; ;;; LISP ADDITIONS ;; the rest of this is in the cl: impromptu library ;;;;;;;;;;;;;;;; ( define cl:first car ) ( define cl:rest cdr ) ( define cl:count length ) ;; reverse of cons: (cons 'b '(a)) ( define cl:l-put ( lambda ( obj lst ) ( reverse ( cons obj ( reverse lst ))))) ;; dont know why but I like it reversed.. ( define cl:nth ( lambda ( x lst ) ( list-ref lst x ))) ( define ( 1 + n ) ( + n 1 )) ( define ( 1 - n ) ( \\ - n 1 )) ;; (subst 9 7 '(5 (5 6 7(6 7)))) => (5 (5 6 9 (6 9))) ( define ( cl:subst new old tree ) ( if ( pair? tree ) ( let (( left ( subst new old ( car tree ))) ( right ( subst new old ( cdr tree )))) ( if ( and ( eq? left ( car tree )) ( eq? right ( cdr tree ))) tree ( cons left right ))) ( if ( eqv? old tree ) new tree ))) ;; (sublis '((6 . 9) (7 . 10)) '(5 (5 6 7 (6 7))))) => (5 (5 9 10 (9 10))) ( define ( cl:sublis alist tree ) ( if ( pair? tree ) ( let (( left ( sublis alist ( car tree ))) ( right ( sublis alist ( cdr tree )))) ( if ( and ( eq? left ( car tree )) ( eq? right ( cdr tree ))) tree ( cons left right ))) ( let (( new ( assv tree alist ))) ( if new ( cdr new ) tree ) ) ) ) ;; (copy-tree '(5 (5 6 7(6 7)))) ( define ( cl:copy-tree x ) ( if ( pair? x ) ( cons ( copy-tree ( car x )) ( copy-tree ( cdr x ))) x )) ; Convert a floating-point number to a string of sign and at most 4 characters. ; Rounds the number so that 1.999 will come out as 2.00 , very small as 0.0 . ; numstring is written assuming that num is not too large or too small, ; i.e. num must be printable in 4 digits. ( define ( cl:numstring num ) ( let \\ * (( numc ( abs num )) ( sign ( if ( < num 0 ) -1 1 )) ( exponent 0 )) ( if ( < numc 1.0 e-6 ) \"0.0\" ( begin ( if ( < numc 1.0 ) ( begin ( while ( < numc 100 ) ( set! numc ( \\ * numc 10 )) ( set! exponent ( 1 - exponent ))) ( set! numc ( \\ * ( round numc ) ( expt 10 exponent ))) ) ( set! numc ( \\ * numc 1.0001 ))) ( if ( < sign 0 ) ( string-append \"-\" ( substring ( number->string numc ) 0 ( min 4 ( string-length ( number->string numc ))))) ( substring ( number->string numc ) 0 ( min 4 ( string-length ( number->string numc ))))) ) ) )) ;(list-flatten '(9 9 (9 9 9 )))) = (9 9 9 9 9) ( define cl:list-flatten ( lambda ( l ) ( cond (( null? l ) ' ()) (( atom? l ) ( list l )) ( #t ( append ( cl:list-flatten ( car l )) ( cl:list-flatten ( cdr l )))))))","title":"Update 28/11/10:"},{"location":"archive/2010/2010-11-09-ryoji-ikeda/","tags":["electronica","ikeda","live"],"text":"Last week I discovered the work of Ryoji Ikeda [ official site ] and soon got hooked up by it. It's kind of strange because if I just listen to the songs without watching the videos that accompany them, they often bore me after a minute or so (with the exception of songs such as data.matrix , or test pattern [[ a really cool live performance of latter at Barcelona's Sonar festival can be found here ) Sounds and video together, instead, produce a fascinating effect: they convey a sense of simplicity and primordial intensity. Through the interaction of flashing lights, disturbing sounds from the technological world, and pure sine waves at extreme high and low frequencies what emerges is a complex pattern that made me wonder about the inner and mysterious workings of our minds. Ikeda's piece called Formula , below, is a good example of this kind of synesthesia-inspired digital art: ... A nice article from Vivian Lee describes the approach of Ikeda in more details: Musician and visual artist Ryoji Ikeda finds his inspiration in data, number arrangements, and the methods of math. Ikeda\u2019s minimalist electronic compositions blend sounds, focusing on specifics such as sine tones and frequencies at the most high and low in the range of human hearing\u2014sound in its \u201craw\u201d state. There are familiar sounds in his work, too: static from the radio, the skipping of scratched CDs, and a television that\u2019s lost its signal. Though Ikeda\u2014who was born in Gifu, Japan, and currently lives and works in Paris\u2014is a musician first, his mathematics-inspired video art is on the rise. Ikeda told the Japan Times that his inspirations come from \u201cMost of the mathematicians in our modern history, especially Leibnitz, Cantor, Godel, Grothendieck.\u201d With modern mathematics in mind, Ikeda developed the idea of datamatics\u2014a series of \u201cexperiments that explore the vast universe of data in the infinite between 0 and 1.\u201d Datamatics first sprung up in 2006 but has been expanded into an hour-long show, weaving sound and video images. Ikeda manipulates these images in real time using custom-designed computer software as the audience looks onto the large screen projections. The data shown on screen is culled from records like NASA (including maps of solar systems) as well as from the Human Genome Project. Along with datamatics, his ongoing dialogue with Harvard mathematician Benedict Gross\u2014in which they explore the mathematical definitions of infinity\u2014led to Ikeda\u2019s data.tron series. In his \u201cdata.tron {3 SXGA + version},\u201d pictured above, he creates an audiovisual installation\u2014three floor-to-ceiling screens of data that physically overwhelms visitors with a staggering array of numbers. Unlike artists who explore in one medium, Ikeda creates multimedia installations at the extremes of sound, light and mathematics . He fuses sound and image in an intensely physical experience, exploiting sound\u2019s physical properties, exploring its relation with human perception, and revealing the aesthetic beauty of pure mathematics. ... A list of other relevant articles can be found here","title":"Ryoji Ikeda"},{"location":"archive/2010/2010-12-09-jmusic-music-composition-in-java/","tags":["composition","java","progression","tutorials"],"text":"jMusic is a project designed to provide composers and software developers with a library of compositional and audio processing tools. It provides a solid framework for computer-assisted composition in Java\u2122, and is also used for generative music, instrument building, interactive performance, and music analysis. I have no intention to leave Scheme and Impromptu, but when I run into jMusic the other day the thing that struck me is the extensive tutorial available on that website (also the references section is worth checking out). I think I'm going to start re-doing all of those exercises with Impromptu, as a learning exercise (btw it marvels me that there's no link to this site on the Impromptu one, given that Andrew Sorensen, the author of impromptu, was working on jMusic too).. In particular there are various interesting sections that focus on how to represent algorithmically classic harmonic progressions. For example, the Chords in the cycle of fifths tutorial. This example plays a progression of dominate seventh chords each a fifth away from the previous chord. In this way each of the 12 notes of the chromatic scale are used once as the root of a chord. This chord progression is common in western musical styles from Baroque to Jazz, and is often called the Cycle of Fifths. The musical result is beautiful; here's how I implemented it in scheme via Impromptu: (define progression '((0 4 -2 -5) (-7) (0 4 7 10) (5))) (define loop (lambda (beat note) (print note) (let ((dur (random '(1 2 4 1/2)))) (begin (for-each (lambda (x) (play dls x 90 dur)) (map (lambda(x) (+ x note)) (list-ref progression 0))) (set! note (+ note (car (list-ref progression 1)))) (for-each (lambda (x) (play (/ dur 2) dls x 90 dur)) (map (lambda(x) (+ x note)) (list-ref progression 2))) (set! note (+ note (car (list-ref progression 3))))) (if (> note 50) (callback (*metro* (+ beat (* 1/2 dur))) 'loop (+ beat dur) note) (for-each (lambda (x) (play (eval dur) dls x 90 dur)) (pc:make-chord-fixed note 4 '(0 4 7 14))) )))) (loop (*metro* 'get-beat) 50) ...","title":"JMusic: music composition in Java"},{"location":"archive/2010/2010-12-09-livecoding-xmas-event-at-goldsmith-college/","tags":["event","goldsmith","livecoding","london"],"text":"Thursday Club Xmas party [ event-site | facebook | flier | map ] The Event \u00b6 6:30pm sharp til 8:30pm, 2010/12/16 at Goldsmith Digital Studios Enjoy live coded music from some of the UKs finest algorithmic musicians, namely: slub - Slub celebrate a decade since they first got a whole room of people to dance to their code (at Amsterdam Paradiso), with a hard-edged set of abstract acid with extra breakdowns. [ http://slub.org/ ] Wrongheaded - Conducting an algorithmic seance, where a ouiji board control interface issues instructions from beyond the grave. Dimly lit but for the flickering of gas-driven projector screens, the protagonists will be appropriately moustachioed as they bring you ethereal sounds from the underworld. Thor Magnusson - Shaking, self-modified beats with ixilang, from the co-founder of ixi audio. [ http://www.ixi-audio.net/ ] Michele Pasin - Audio/Visual temporal recursion with Impromptu. [ http://www.michelepasin.org/ ] Forth + Yee-King - South Bank Common Lisp + SuperCollider synchronised in percussive improv. [ http://www.yeeking.net/ ] About livecoding \u00b6 Live coding is a new direction in electronic music and video, and is starting to get somewhere interesting. Live coders expose and rewire the innards of software while it generates improvised music and/or visuals. All code manipulation is projected for your pleasure. Live coding is inclusive and accessible to all. Many live coding environments can be downloaded and used for free, with documentation and examples to get you started and friendly on-line communities to help when you get problems. Popular live coding software includes supercollider, ChucK, impromptu and fluxus. Live patching is live coding with graph-based languages such as the venerable pure-data. It's also possible to livecode with a gamepad, e.g. with the robot oriented Al-Jazari. For more info see: http://toplap.org/","title":"Livecoding Xmas event at Goldsmith College"},{"location":"archive/2010/2010-12-09-livecoding-xmas-event-at-goldsmith-college/#the-event","text":"6:30pm sharp til 8:30pm, 2010/12/16 at Goldsmith Digital Studios Enjoy live coded music from some of the UKs finest algorithmic musicians, namely: slub - Slub celebrate a decade since they first got a whole room of people to dance to their code (at Amsterdam Paradiso), with a hard-edged set of abstract acid with extra breakdowns. [ http://slub.org/ ] Wrongheaded - Conducting an algorithmic seance, where a ouiji board control interface issues instructions from beyond the grave. Dimly lit but for the flickering of gas-driven projector screens, the protagonists will be appropriately moustachioed as they bring you ethereal sounds from the underworld. Thor Magnusson - Shaking, self-modified beats with ixilang, from the co-founder of ixi audio. [ http://www.ixi-audio.net/ ] Michele Pasin - Audio/Visual temporal recursion with Impromptu. [ http://www.michelepasin.org/ ] Forth + Yee-King - South Bank Common Lisp + SuperCollider synchronised in percussive improv. [ http://www.yeeking.net/ ]","title":"The Event"},{"location":"archive/2010/2010-12-09-livecoding-xmas-event-at-goldsmith-college/#about-livecoding","text":"Live coding is a new direction in electronic music and video, and is starting to get somewhere interesting. Live coders expose and rewire the innards of software while it generates improvised music and/or visuals. All code manipulation is projected for your pleasure. Live coding is inclusive and accessible to all. Many live coding environments can be downloaded and used for free, with documentation and examples to get you started and friendly on-line communities to help when you get problems. Popular live coding software includes supercollider, ChucK, impromptu and fluxus. Live patching is live coding with graph-based languages such as the venerable pure-data. It's also possible to livecode with a gamepad, e.g. with the robot oriented Al-Jazari. For more info see: http://toplap.org/","title":"About livecoding"},{"location":"archive/2010/2010-12-21-new-song-turborobot/","tags":["electronica","livecoding","song"],"text":"It's a bit of an electro/eighties-sounding/disco tune.. Here's the live-coded version: And here's an audio recording, for the faint-hearted: Turborobot by magicrebirth","title":"New song: Turborobot"},{"location":"archive/2011/2011-01-21-live-coding-in-clojure/","tags":["clojure","livecoding","processing"],"text":"Live-processing is a Processing clone with livecode capabilities. It's written in Clojure, a recent java-based dynamic programming language which I reviewed elsewhere and it keeps getting back at me...","title":"Live coding in clojure"},{"location":"archive/2011/2011-01-29-opening-a-finders-window-from-impromptu-alas-how-to-use-the-applescript-bridge/","tags":["applescript","finder","impromptu","objc","programming-2","scheme"],"text":"Imagine you've got a bunch of audio samples you want to load up while livecoding with Impromptu but you can't remember exactly their names - it'd be handy to be able to open up the corresponding Finder window directly from scheme, without too much clicking around. Do-able or not? I spent some time trying to figure this out, and the answer is yes! Quite a nice learning experience... although it came with a surprise at the end. Originally I thought, let's do it via impromptu's ObjC bridge . I don't know much about ObjC but after a bit of googling it seemed evident that the quickest way to accomplish this is by writing ObjC code that, in turns, runs a simple applescript command that opens a window: [ NSString ]( http : //developer.apple.com/documentation/Cocoa/Reference/Foundation/Classes/NSString_Class/) \\*s \\= \\[[NSString](http://developer.apple.com/documentation/Cocoa/Reference/Foundation/Classes/NSString_Class/) stringWithFormat: @ \"tell application \" Terminal \" to do script \" cd % @ \"\" , folderPath ]; [ NSAppleScript ]( http : //developer.apple.com/documentation/Cocoa/Reference/Foundation/Classes/NSAppleScript_Class/) \\*as \\= \\[\\[[NSAppleScript](http://developer.apple.com/documentation/Cocoa/Reference/Foundation/Classes/NSAppleScript_Class/) alloc\\] initWithSource: s\\]; [ as executeAndReturnError : nil ]; So I translated the bottom part of the code above into impromptu/scheme: ( define run_applescript ( lambda ( script ) ( objc:call ( objc:call ( objc:call \"NSAppleScript\" \"alloc\" ) \"initWithSource:\" script ) \"executeAndReturnError:\" ))) That is a generic script-running function, that is, you can pass any script and it 'll run it, eg: ( define script0 \" tell application \" Finder \" to open folder \" Macintosh HD:Users \" tell application \" Finder \" to activate\" ) ( define script1 \" tell application \" Terminal \" to do script \" cd ~ ; open .\"\") ( define script2 \" tell application \" System Events \"n tell dock preferencesn set properties to {autohide:false}n end telln end tell\" ) ;; finally, let's choose randomly one of the scripts above and run it ( run_applescript ( random ' ( script0 script1 script2 ))) Now, back to the original problem: in order to open a Finder's window at a specified location we need to pass the location variable to our function run_applescript ; also, we want to be able to pass unix path expressions (eg '/Users/mike/music/'), so we've got to transform that path syntax into the semicolon-delimited macintosh syntax (\"Macintosh HD:Users:mike:music\") needed by the applescript function we're using. That's easily done with string-replace , so here we go: ( define open_finder_at ( lambda ( location ) ( let* (( llocation ( string-replace location \"/\" \":\" )) ( script ( string-append \"tell application \" Finder \" to activate open folder \" Macintosh HD \" llocation \"\"\" ))) ( objc:call ( objc:call ( objc:call \"NSAppleScript\" \"alloc\" ) \"initWithSource:\" script ) \"executeAndReturnError:\" )))) ( open_finder_at \"/Users/me/\" ) That's pretty much it really... now we can easily open OsX Finder's windows from within Impromptu. But as I said above, there's a surprise: after getting this far I thought I'd search impromptu's mailing list for more examples of obj:call .... and guess what, there's already a system function that runs applescripts, it's called sys:run-applescript ! Too bad, it's been a rewarding learning experience anyways...","title":"Opening a Finder's window from Impromptu (alas how to use the applescript bridge..)"},{"location":"archive/2011/2011-02-07-what-is-the-reaper-time-in-impromptu/","tags":["impromptu","latency","reaper","settings"],"text":"I got this info while reading Kontakt 4 documentation, and I thought it was useful to pass it on. It helps understanding the significance of the 'reaper time' setting in Impromptu, which I often playing around with without really getting it... (check Reaper stuff on IM mailing list). Kontakt 4 is an aaward winning sampler from Native Instrument; I was just going through the docs the other day to figure out what it does or doesn't do and in the section that explain the various ettings parameters I found the description of the 'latency optimization' very useful (2.1.2 Latency Optimization [KONTAKT 4 Getting Started \u2013 page 11 - get the pdf of the manual here) . The Latency slider controls the size of the playback buffer. And here is the explanation of that setting: The load that typical digital audio calculations generate on your processor is often not constant and predictable; parameter changes, additional voices or other processes can all cause mo- mentary peaks in the load, which can result in drop-outs or other audio artifacts if not properly compensated for. That is why audio programs do not send the audio signals they generate directly to the hardware, but write them to a short buffer in memory instead, whose contents are in turn being sent to the actual hardware. This concept allows the program to bridge short irregularities in the stream calculation and thus be more resistant to processing peaks. Of course, this \u201csafety net\u201d comes at a price\u2013the buffering causes a delay, known as latency , between the triggering of a note and the actual sound. This delay gets longer with increas- ing buffer sizes. Hence, it\u2019s vital to tune the buffer size in order to find a good compromise between latency and playback reliability. The optimal value depends on such diverse factors as your CPU, memory and hard disk access times, your audio hardware and drivers, and your operating system environment. In order to find the optimal buffer size for your system, we recommend that you begin by setting the Latency slider described in the previous section to a healthy middle value between 384 and 512 samples, then gradually decrease the value during your normal work. When you begin to notice drop-outs, increase the buffer again by a small amount. Generally, it\u2019s a good idea to have as few other applications as possible running in the back- ground when working with audio software. Also, if you can\u2019t get below a certain buffer size without getting drop-outs, consult the documentation of your audio hardware to find out whether you can access it via an alternate driver architecture, as some architectures allow more efficient low-level access to the hardware than others.","title":"What is the reaper time in Impromptu?"},{"location":"archive/2011/2011-02-24-new-livecoding-documentary-available/","tags":["documentary","film","livecoding"],"text":"A nice documentary about livecoding practise by Louis McCallum and Davy Smith . Some shorts excepts from my performance at the Anatomy Museum are included too (00:32 and 08:45). Show Us Your Screens on Vimeo .","title":"'Show us your screens': new Livecoding documentary"},{"location":"archive/2011/2011-03-29-an-alternative-to-the-play-macro-iplay-and-with-instrument/","tags":["impromptu","macro","play"],"text":"The other day I was thinking: when I use the play macro in Impromptu [ video tutorial ], in my head it's already obvious what's the virtual instrument I want to play. So why do I have to specify that all the time? Wouldn't it be more natural just being able to say, for example, get this instrument and now play this and that note with it ... Let me clarify this with an example. Let's set up the standard Apple's DLS-synth audiounit and the metronome: (au:clear-graph) (define dls (au:make-node \"aumu\" \"dls \" \"appl\")) (au:connect-node dls 0 *au:output-node* 0) (au:update-graph) (au:print-graph) (define *metro* (make-metro 100)) Now imagine that we want to play some (dumb) melody with Apple's DLS. We can use the usual play macro to achieve this quite easily (that's because above we set up the metronome, which is needed in order to use play - check out the docs if this sounds odd to you). Sequencing a bunch of notes is thus just a matter of sequencing play macros: (define the-usual-play (lambda (beat) (play dls 60 90 1) (play dls 64 90 1) (play 1/2 dls 72 90 1) (play 3/2 dls 67 90 1) (callback (*metro* (+ beat (* 1/2 2))) 'the-usual-play (+ beat 2)))) (the-usual-play (*metro* 'get-beat 4)) That's where I started getting nervous (so to say). Having to write 'dls' each time I play a new note seemed to me redundant and illogical; I know that it's dls the instrument I want to play - I heard my mind screaming - why can't I focus on the music instead of making sure I type in the instrument name all the time? Taking advantage of Scheme, the self-modifying language \u00b6 Luckily though we're using Scheme , which differently from most other computer languages allows you to change the language grammar as you like, thanks to macros . So here we go, we can create a new macro similar to play that lets you omit the instrument you're playing. We'll call it iplay (shortcut for instrument-play, not itunes :-)): (macro (iplay args) (cond ((equal? (length (cdr args)) 3) `(let ((note ,(cadr args)) (vol ,(caddr args)) (dur ,(cadddr args)) ) (play my-inst note vol dur))) ((equal? (length (cdr args)) 4) `(let ((offset ,(cadr args)) (note ,(caddr args)) (vol ,(cadddr args)) (dur ,(cadddr (cdr args)))) (play (eval offset) my-inst note vol dur))) (#t (print \"Error: the function only accepts 3 or 4 argument\")))) Essentially what we're telling the interpreter here is that every time iplay is used, the original play should be called and the symbol my-inst should be passed as the variable representing our instrument. Now we can modify the simple loop defined above like this: (define the-usual-play-modified (lambda (beat) (let ((my-inst dls)) (iplay 60 90 1) (iplay 64 90 1)) (play 1/2 dls 72 90 1) (play 3/2 dls 67 90 1) (callback (*metro* (+ beat (* 1/2 2))) 'the-usual-play-modified (+ beat 2)))) (the-usual-play-modified (*metro* 'get-beat 4)) If you run that, you'll see that this loop sounds exactly the same as the previous one, although the first two play calls are now iplay macro calls. The whole thing works because we introduced a local variable my-inst and bound that to the dls audio instrument (created at the beginning). Notice that the new macro iplay knows nothing about what instrument is playing : it's just using blindly the my-inst variable, under the assumption that we've associated it to a valid audio instrument. Some more syntactic sugar \u00b6 The only hassle now is that each time we want to use iplay we are forced to use the (let ((my-inst dls)).. form. Typing this stuff doesn't feel very natural too. Rather, in my head, I tend to see things like this: get an instrument first, then play a bunch of notes with it. So, let's create some syntactic sugar for the ' let ' form, by defining another macro, ' with-instrument ': (macro (with-instrument args) `(let ((my-inst ,(cadr args))) ,@(cddr args))) As you can see, this macro doesn't do much: it just rephrases the let form above in a way that is probably more natural to me (and to others too I believe..). For example, now we can use iplay like this: (define justatest (lambda (beat) (with-instrument dls (iplay 48 40 1) ;; iplay with 3 args: pitch, vol and dur (iplay (random (list 1/2 1/4 1/8)) (random 60 80) 40 1)) ;; 4 arguments: offset (callback (*metro* (+ beat (* 1/2 1))) 'justatest (+ beat 1)))) (justatest (*metro* 'get-beat 4)) Finally, let's remember that because of the way we defined iplay above, we can pass it 3 or 4 arguments: in the first case, the macro assumes that we're providing a pitch , a volume , and a duration . In the second case instead the first argument is assumed to be an offset value (while the others remain unchanged). The original play macro can take another argument too: the channel (or midi port). I haven't included here cause I normally don't need it, but if you do I'm sure you can fiddle a bit with the code above and make it do whatever you want! Conclusion: here is the code you need to evaluate within Impromptu if you want to use the with/iplay constructs (all the source code is also available on BitBucket ): (macro (with-instrument args) `(let ((my-inst ,(cadr args))) ,@(cddr args))) (macro (iplay args) (cond ((equal? (length (cdr args)) 3) `(let ((note ,(cadr args)) (vol ,(caddr args)) (dur ,(cadddr args)) ) ;(print inst beat note vol dur) (play my-inst note vol dur))) ((equal? (length (cdr args)) 4) `(let ((offset ,(cadr args)) (note ,(caddr args)) (vol ,(cadddr args)) (dur ,(cadddr (cdr args)))) ;(print inst beat note vol dur) (play (eval offset) my-inst note vol dur))) (#t (print \"Error: the function only accepts 3 or 4 argument\")))) Finally.. a 'pastebin' function \u00b6 Also, here is a pastebin function similar to pb:cb (check out this video tutorial if you don't know what I'm talking about) that returns a template with the with-instrument macro: (define pb:iplay (lambda (name dur inst) '())) ;; fake function definition, useful for autocompletion! ;; macro wrapper for pb-iplay (define-macro (pb:iplay name dur inst . args) `(pb-iplay (sexpr->string (quote ,name)) (sexpr->string (quote ,dur)) (sexpr->string (quote ,inst)) ,@(map (lambda (expr) (sexpr->string expr)) args))) (define pb-iplay (lambda (name dur inst . args) (let ((a (apply string-append (map (lambda (e) (string-append \"n \" e)) args)))) (sys:set-pasteboard (string-append \"(define \" name \" (lambda (beat) (with-instrument \" inst \" \" a \" (callback (*metro* (+ beat (* 1/2 \" dur \"))) '\" name \" (+ beat \" dur \")))))nn(\" name \" (*metro* 'get-beat 4))\"))))) ;;;;;;;;;;;;;;;; ;; call it like this: ;(pb:iplay myloop 1/4 dls) ;; ;;;;;;;;;;;;;;;;; ;; returns: ;;;;;;;;;;;;;;;; ; ;(define myloop ; (lambda (beat) ; (with-instrument dls ; ; (callback (*metro* (+ beat (* 1/2 1/4))) 'myloop (+ beat 1/4))))) ; ;(myloop (*metro* 'get-beat 4))","title":"An alternative to the 'play' macro: 'iplay' and 'with-instrument'"},{"location":"archive/2011/2011-03-29-an-alternative-to-the-play-macro-iplay-and-with-instrument/#taking-advantage-of-scheme-the-self-modifying-language","text":"Luckily though we're using Scheme , which differently from most other computer languages allows you to change the language grammar as you like, thanks to macros . So here we go, we can create a new macro similar to play that lets you omit the instrument you're playing. We'll call it iplay (shortcut for instrument-play, not itunes :-)): (macro (iplay args) (cond ((equal? (length (cdr args)) 3) `(let ((note ,(cadr args)) (vol ,(caddr args)) (dur ,(cadddr args)) ) (play my-inst note vol dur))) ((equal? (length (cdr args)) 4) `(let ((offset ,(cadr args)) (note ,(caddr args)) (vol ,(cadddr args)) (dur ,(cadddr (cdr args)))) (play (eval offset) my-inst note vol dur))) (#t (print \"Error: the function only accepts 3 or 4 argument\")))) Essentially what we're telling the interpreter here is that every time iplay is used, the original play should be called and the symbol my-inst should be passed as the variable representing our instrument. Now we can modify the simple loop defined above like this: (define the-usual-play-modified (lambda (beat) (let ((my-inst dls)) (iplay 60 90 1) (iplay 64 90 1)) (play 1/2 dls 72 90 1) (play 3/2 dls 67 90 1) (callback (*metro* (+ beat (* 1/2 2))) 'the-usual-play-modified (+ beat 2)))) (the-usual-play-modified (*metro* 'get-beat 4)) If you run that, you'll see that this loop sounds exactly the same as the previous one, although the first two play calls are now iplay macro calls. The whole thing works because we introduced a local variable my-inst and bound that to the dls audio instrument (created at the beginning). Notice that the new macro iplay knows nothing about what instrument is playing : it's just using blindly the my-inst variable, under the assumption that we've associated it to a valid audio instrument.","title":"Taking advantage of Scheme, the self-modifying language"},{"location":"archive/2011/2011-03-29-an-alternative-to-the-play-macro-iplay-and-with-instrument/#some-more-syntactic-sugar","text":"The only hassle now is that each time we want to use iplay we are forced to use the (let ((my-inst dls)).. form. Typing this stuff doesn't feel very natural too. Rather, in my head, I tend to see things like this: get an instrument first, then play a bunch of notes with it. So, let's create some syntactic sugar for the ' let ' form, by defining another macro, ' with-instrument ': (macro (with-instrument args) `(let ((my-inst ,(cadr args))) ,@(cddr args))) As you can see, this macro doesn't do much: it just rephrases the let form above in a way that is probably more natural to me (and to others too I believe..). For example, now we can use iplay like this: (define justatest (lambda (beat) (with-instrument dls (iplay 48 40 1) ;; iplay with 3 args: pitch, vol and dur (iplay (random (list 1/2 1/4 1/8)) (random 60 80) 40 1)) ;; 4 arguments: offset (callback (*metro* (+ beat (* 1/2 1))) 'justatest (+ beat 1)))) (justatest (*metro* 'get-beat 4)) Finally, let's remember that because of the way we defined iplay above, we can pass it 3 or 4 arguments: in the first case, the macro assumes that we're providing a pitch , a volume , and a duration . In the second case instead the first argument is assumed to be an offset value (while the others remain unchanged). The original play macro can take another argument too: the channel (or midi port). I haven't included here cause I normally don't need it, but if you do I'm sure you can fiddle a bit with the code above and make it do whatever you want! Conclusion: here is the code you need to evaluate within Impromptu if you want to use the with/iplay constructs (all the source code is also available on BitBucket ): (macro (with-instrument args) `(let ((my-inst ,(cadr args))) ,@(cddr args))) (macro (iplay args) (cond ((equal? (length (cdr args)) 3) `(let ((note ,(cadr args)) (vol ,(caddr args)) (dur ,(cadddr args)) ) ;(print inst beat note vol dur) (play my-inst note vol dur))) ((equal? (length (cdr args)) 4) `(let ((offset ,(cadr args)) (note ,(caddr args)) (vol ,(cadddr args)) (dur ,(cadddr (cdr args)))) ;(print inst beat note vol dur) (play (eval offset) my-inst note vol dur))) (#t (print \"Error: the function only accepts 3 or 4 argument\"))))","title":"Some more syntactic sugar"},{"location":"archive/2011/2011-03-29-an-alternative-to-the-play-macro-iplay-and-with-instrument/#finally-a-pastebin-function","text":"Also, here is a pastebin function similar to pb:cb (check out this video tutorial if you don't know what I'm talking about) that returns a template with the with-instrument macro: (define pb:iplay (lambda (name dur inst) '())) ;; fake function definition, useful for autocompletion! ;; macro wrapper for pb-iplay (define-macro (pb:iplay name dur inst . args) `(pb-iplay (sexpr->string (quote ,name)) (sexpr->string (quote ,dur)) (sexpr->string (quote ,inst)) ,@(map (lambda (expr) (sexpr->string expr)) args))) (define pb-iplay (lambda (name dur inst . args) (let ((a (apply string-append (map (lambda (e) (string-append \"n \" e)) args)))) (sys:set-pasteboard (string-append \"(define \" name \" (lambda (beat) (with-instrument \" inst \" \" a \" (callback (*metro* (+ beat (* 1/2 \" dur \"))) '\" name \" (+ beat \" dur \")))))nn(\" name \" (*metro* 'get-beat 4))\"))))) ;;;;;;;;;;;;;;;; ;; call it like this: ;(pb:iplay myloop 1/4 dls) ;; ;;;;;;;;;;;;;;;;; ;; returns: ;;;;;;;;;;;;;;;; ; ;(define myloop ; (lambda (beat) ; (with-instrument dls ; ; (callback (*metro* (+ beat (* 1/2 1/4))) 'myloop (+ beat 1/4))))) ; ;(myloop (*metro* 'get-beat 4))","title":"Finally.. a 'pastebin' function"},{"location":"archive/2011/2011-04-09-a-space-odyssey-live-with-philharmonia-orchestra/","tags":["film","kubrick","live","london"],"text":"Went to the SouthBank Centre the other night, to see Kubrick's 2001: A Space Odyssey Live with Philharmonia Orchestra. Very very nice, almost moving even if I've seen the movie a dozen times already! Following a sell-out success in June 2010, Southbank Centre presents Stanley Kubrick\u2019s seminal film 2001: A Space Odyssey with live music. Conducted by Andr\u00e9 de Ridder , the enormous forces of Philharmonia Orchestra and Philharmonia Voices join together to perform the film\u2019s extraordinary soundtrack, as live accompaniment to a screening in Royal Festival Hall. Long recognised as one of the greatest science fiction films of all time, 2001 \u2013 A Space Odyssey is celebrated for its technological realism, its innovative Oscar-winning special effects and a bold use of music . The film brought worldwide fame to both Richard Strauss\u2019 Also Sprach Zarathustra and the music of Gyorgy Ligeti; it also created one of cinema\u2019s most memorable images as a spaceship floats serenely through space to the strains of Johann Strauss\u2019 Blue Danube waltz. Here's an excerpt from last night's performance:","title":"A Space Odyssey Live with Philharmonia Orchestra"},{"location":"archive/2011/2011-04-16-ether-festival/","tags":["festival","live","london"],"text":"I went to SouthBank for the Ether festival the other night, and caught two very inspiring performances by Anna Meredith and James Blake (among others). Anna Meredith \u00b6 Anna Meredith [homepage] is a composer and performer of electronic and acoustic music. Her acoustic material has been performed around the world by many leading orchestras and ensembles. She has been composer in residence with the BBC Scottish Symphony Orchestra and is currently the PRS/RPS Composer in the House with Sinfonia ViVA . Nautilus by Anna Meredith She came to public attention through her 2008 work froms for the BBC Last Night of the Proms and has since written another BBC Prom commission, her first opera (Tarantula in Petrol Blue - with libretto by Philip Ridley) and collaborated with the beatboxer Shlomo - writing the acclaimed Concerto for Beatboxer and Orchestra. Anna is also a judge for the BBC Young Musician of the Year, a mentor for Goldie for the TV show Classic Goldie and a frequent guest and commentator for the BBC Proms and other Radio 3 and 4 shows. James Blake \u00b6 James Blake [ wikipedia | homepage | youtube ]is a British electronic composer from London, UK. James began his final year at Goldsmiths in September 2009 studying popular music while recording songs in his bedroom. Blake attended The Latymer School and released his debut 12\u201d \u201cAir and Lack Thereof\u201d on Hemlock Audio in July 2009. It was a firm favourite with Gilles Peterson from BBC Radio 1. James was invited to do a special mix on Gilles Peterson\u2019s worldwide show which included an exclusive Mount Kimbie track. On 6 January 2011, Blake was announced as runner-up in BBC's Sound of 2011 poll[1]. His self-titled debut album was released in the UK on 7 February 2011 a review here . The performance the other night at the Purcell Room was magical: I found this video on youtube, it's not very good but the sound is ok: Tim Exile \u00b6 http://www.timexile.co.uk/ I've never heard about this electronic artist [ homepage ] before - but the other day I saw his name on the Ether festival program and got interested, so I looked for some his stuff online. Well, it's a pretty interesting character I must say! Real sorry to have missed his performance at Southbank. Definitely worth checking out his stuff.. he's now also working with electronic instruments seller Native Instruments (eg check out 'The Mouth' virtual instrument: video#1 and video#2 .. very funny!).","title":"Ether festival"},{"location":"archive/2011/2011-04-16-ether-festival/#anna-meredith","text":"Anna Meredith [homepage] is a composer and performer of electronic and acoustic music. Her acoustic material has been performed around the world by many leading orchestras and ensembles. She has been composer in residence with the BBC Scottish Symphony Orchestra and is currently the PRS/RPS Composer in the House with Sinfonia ViVA . Nautilus by Anna Meredith She came to public attention through her 2008 work froms for the BBC Last Night of the Proms and has since written another BBC Prom commission, her first opera (Tarantula in Petrol Blue - with libretto by Philip Ridley) and collaborated with the beatboxer Shlomo - writing the acclaimed Concerto for Beatboxer and Orchestra. Anna is also a judge for the BBC Young Musician of the Year, a mentor for Goldie for the TV show Classic Goldie and a frequent guest and commentator for the BBC Proms and other Radio 3 and 4 shows.","title":"Anna Meredith"},{"location":"archive/2011/2011-04-16-ether-festival/#james-blake","text":"James Blake [ wikipedia | homepage | youtube ]is a British electronic composer from London, UK. James began his final year at Goldsmiths in September 2009 studying popular music while recording songs in his bedroom. Blake attended The Latymer School and released his debut 12\u201d \u201cAir and Lack Thereof\u201d on Hemlock Audio in July 2009. It was a firm favourite with Gilles Peterson from BBC Radio 1. James was invited to do a special mix on Gilles Peterson\u2019s worldwide show which included an exclusive Mount Kimbie track. On 6 January 2011, Blake was announced as runner-up in BBC's Sound of 2011 poll[1]. His self-titled debut album was released in the UK on 7 February 2011 a review here . The performance the other night at the Purcell Room was magical: I found this video on youtube, it's not very good but the sound is ok:","title":"James Blake"},{"location":"archive/2011/2011-04-16-ether-festival/#tim-exile","text":"http://www.timexile.co.uk/ I've never heard about this electronic artist [ homepage ] before - but the other day I saw his name on the Ether festival program and got interested, so I looked for some his stuff online. Well, it's a pretty interesting character I must say! Real sorry to have missed his performance at Southbank. Definitely worth checking out his stuff.. he's now also working with electronic instruments seller Native Instruments (eg check out 'The Mouth' virtual instrument: video#1 and video#2 .. very funny!).","title":"Tim Exile"},{"location":"archive/2011/2011-05-02-the-new-livecoding-error-hook-in-impromptu/","tags":["impromptu","performance","tips"],"text":"Impromptu 2.5 has been out for a while now but I've never realised it contained this new handy feature: an 'error hook': The interpreter will now throw to an error hook providing you with greater control over exception handling. You initiate the livecoding error hook by calling (sys:livecoding-error-hook #t). Errors are then passed to the *livecoding-error-hook* function - which you may rebind. By default the function simply returns 1 but can be modified for more specialised behaviour. This is extremely useful, to say the least, if you are performing live and want to avoid situations in which a (stupid) typo or parenthesis error will mess up your entire gig. The error hook in many cases will prevent your looping function from crashing, giving you time to fix the error. Really neat. Here's an example from the official release notes: ;; turn on livecoding error hook ( sys:livecoding-error-hook #t ) ;; with livecoding-error-hook on ;; this temporal recursion will continue ;; to play the second note even though 'pitch ;; is an unbound symbol ( define loop ( lambda ( beat ) ;; symbol a is not bound but loop continues to function ( play piano pitch 80 1 ) ( play piano 63 80 1 ) ( callback ( *metro* ( + beat ( * 1 /2 1 ))) 'loop ( + beat 1 )))) ( loop ( *metro* 'get-beat 4 )) ;; by redefining the error hook we can provide ;; additional specialisation - such as replacing ;; any unbound symbol with 60! ;; ;; eval below and both notes will play ;; 'pitch being replaced by 60 ( define *livecoding-error-hook* ( lambda ( msg a ) ( cond (( symbol? a ) 60 ) ( else 0 )))) Happy (and safer) livecoding!","title":"The new Livecoding Error Hook in Impromptu"},{"location":"archive/2011/2011-06-19-enabling-web-audio-in-chrome/","tags":["audio","chrome","html5","web"],"text":"I haven't realized that Chrome has a whole bunch of invisible experimental settings that you can turn on just by going to \" about:flags \". Some of them will open up the musical capabilities of html5, which are pretty cool. Example, once you switch on the ' web-audio ' setting on Chrome, if you use a suitable musical musical library you could play a note just by issuing these javascript commands: var n = Note.fromLatin('A4'); var freq = n.frequency(); // returns 440 var name = n.latin(); // returns \"A\" var octave = n.octave(); // returns 4 The full example (with sound, if you've turned on the Web Audio setting as mentioned above) can be seen here: musicjs demo . More info about web audio and related stuff can be found on this blog post: http://pixelist.info/web-audio-it-is-finally-almost-here/","title":"Enabling web-audio in Chrome"},{"location":"archive/2011/2011-06-26-bjork-redefines-the-musicians-product-with-biophilia-albumapp/","tags":["app","electronica","ipad","music"],"text":"I found out here and there on the web that Islandic artist Bjork is once again pushing the boundaries of experimental music by relasing a new album, Biophilia , which will be composed by both music and interactive media, in the form of an iPad app: Biophilia for iPad will include around 10 separate apps, all housed within one \"mother\" app . Each of the smaller apps will relate to a different track from the album, allowing people to explore and interact with the song's themes or even make a completely new version. It will also be an evolving entity that will grow as and when the album's release schedule dictates, with new elements added. Scott Snibbe, an interactive artist who was commissioned by Bj\u00f6rk last summer to produce the app, as well as the images for the live shows (which will combine his visuals with National Geographic imagery, mixed live from iPads on the stage), describes how Bj\u00f6rk saw the possibilities of using apps, not as separate to the music, but as a vital component of the whole project. \"Bj\u00f6rk's put herself way at the forefront here by saying, 'We'll release this album and these apps at the same time and they're all part of the same story.' The app is an expression of the music, the story and the idea.\" The review above is taken from an article on posterous.com . How will the music/apps look like? Here's an example: For one song, Virus, the app will feature a close-up study of cells being attacked by a virus to represent what Snibbe calls : \"A kind of a love story between a virus and a cell. And of course the virus loves the cell so much that it destroys it.\" The interactive game challenges the user to halt the attack of the virus, although the result is that the song will stop if you succeed. In order to hear the rest of the song, you have to let the virus take its course. Using some artistic license, the cells will also mouth along to the chorus. It's this determination to fuse different elements together \u2013 be it juxtaposing a female choir from Greenland with the bleeps and glitches of electronic music pioneers Matmos during the Vespertine tour, or meshing soaring strings and jagged beats on the Homogenic album \u2013 that helps explain the power and success of Bj\u00f6rk's collaborations..... Biophilia is the result of a collaboration with Scott Sona Snibble , a digital artist active in the app-world with products such as 'OscilloScoop': More press coverage on Pitchfork and the Guardian .","title":"Bjork redefines the musician's product with 'Biophilia' album/app"},{"location":"archive/2011/2011-06-29-livecoding-is-like-gardening/","tags":["composing","eno","livecoding","quote"],"text":"Just ran into this interesting article by Brian Eno . It struck me as quite a fair representation of what livecoders do most of the time, when they create (maybe I should say 'sculpt') musical structures that evolve in time, as part of their performance: It\u2019s intuitive to think that anything complex has to be made by something more complex, but evolution theory says that complexity arises out of simplicity. That\u2019s a bottom-up picture. I like that idea as a compositional idea, that you can set in place certain conditions and let them grow. It makes composing more like gardening than architecture It's from http://www.soundonsound.com/sos/oct05/articles/brianeno.htm . Here is one of the songs from the album Eno is talking about in that article, Another Day on Earth .","title":"Livecoding is like gardening"},{"location":"archive/2011/2011-07-08-livecoding-in-paris-stransbourg/","tags":["live","paris","strasbourg"],"text":"Two livecoding concerts coming up in the next days: 9/7/11: A gig in Paris at La Generale , \"Laboratoire artistique, politique et social\". 14, avenue Parmentier Paris XIe, M\u00e9tro Voltaire ( facebook | lastfm ) 11/7/11: A workshop+gig at the 2011 Libre Software Meeting in Stransbourg ( event page | facebook | lastfm ). I'm going to play a new livecoded song called ' Fjords '. During the last days I've also finalized several little things that make livecoding with Impromptu faster (and easier, at least for me), which is good, so I'm aiming at making available those too in the coming days... Btw I'll try to take videos of the various performances, so stay tuned! [ Update 11/7/11 ] Here's a recording of the Paris gig:","title":"Livecoding in Paris & Strasbourg"},{"location":"archive/2011/2011-07-11-workshop-on-live-coding-rmll-11/","tags":["livecoding","strasbourg"],"text":"I just got back from Strasbourg (France) where I gave a talk about my experience with Livecoding and Impromptu at the at the Cultures et Arts Libres Workshop, part of the 2011 Libre Software Meeting . In a nutshell, livecoding is the process of writing software in realtime, as a form of improvised time-based art. Many thanks for the organizers for inviting me, it's been a quite rewarding experience. Here I'm posting the slides from the talk in case people want to follow up on the things I mentioned. The slides are very introductory, so I strongly encourage anyone interested to find out more about the world of Impromptu by following the links provided in the presentation. Livecoding with impromptu The other two livecoders who gave talks at the workshop were Marje Baalman and Dan Stowell ; both of them do very interesting stuff with SuperCollider (another livecoding environment) so you better check them out too! By the way, after the workshop there was also a livecoding performance - but I'm going to report about that here ..","title":"Workshop on Live Coding @ RMLL-11"},{"location":"archive/2011/2011-10-06-article-algorithmic-composition-computational-thinking-in-music/","tags":["algorithmiccomposition","article","ideas","serialism"],"text":"An article by Michael Edwards on algorithmic composition has been published last month on the Communications of the ACM journal. The article is titled Algorithmic Composition: Computational Thinking in Music . Although the article is quite introductory (Edwards makes it clear that the article \"is more illustrative than all-inclusive, presenting examples of particular techniques and some of the music that has been produced with them\") it is defintely an interesting read. I found quite a few nice ideas in it and also references to musics and musicians I wasn't familiar with. Follows a list of 'highlights' from my iPad reader, to which I added hyperlinks to relevant explanatory materials: SERIALISM AS A CONTINUATION OF EARLY ALGORITHMIC COMPOSITION After World War II, many Western classical music composers continued to develop the serial technique invented by Arnold Sch\u00f6nberg (1874\u20131951) et al. Though generally seen as a radical break with tradition, in light of the earlier historical examples just presented, serialism\u2019s detailed organization can be viewed as no more than a continuation of the tradition of formalizing musical composition. Indeed, one of the new generation\u2019s criticisms of Sch\u00f6nberg was that he radicalized only pitch structure, leaving other parameters (such as rhythm, dynamic, even form) in the 19th century. They looked to the music of Sch\u00f6nberg\u2019s pupil Anton von Webern for inspiration in organizing these other parameters according to serial principles. Hence the rise of the total serialists: Boulez , Stockhausen , Pousseur , Nono , and others in Europe, and Milton Babbitt and his students at Princeton. COMPOSERS: HILLER AND \"THE ILLIAC SUITE FOR STRING QUARTET\" Lejaren Hiller (1924\u20131994) is widely recognized as the first composer to have applied computer programs to algorithmic composition. The use of specially designed, unique computer hardware was common at U.S. universities in the mid-20th century. Hiller used the Illiac computer at the University of Illinois, Urbana-Champaign, to create experimental new music with algorithms. His collaboration with Leonard Isaacson resulted in 1956 in the first known computer-aided composition, The Illiac Suite for String Quartet ( wiki | video ), programmed in binary, and using, among other techniques, Markov Chains in \u201crandom walk\u201d pitch generation algorithms. CAGE ON THE DIFFERENCE BETWEEN TRADITIONAL AND COMPUTER- ASSISTED COMPOSITION Cage said in an interview during the composition of HPSCHD ( wiki | video ), \"Formerly, when one worked alone, at a given point a decision was made, and one went in one direction rather than another; whereas, in the case of working with another person and with computer facilities, the need to work as though decisions were scarce\u2014as though you had to limit yourself to one idea\u2014is no longer pressing. It\u2019s a change from the influences of scarcity or economy to the influences of abundance and - I\u2019d be willing to say\u2014waste.\" COMPOSERS: XENAKIS Known primarily for his instrumental compositions but also as an engineer and architect, Iannis Xenakis was a pioneer of algorithmic composition and computer music. Using language typical of the sci-fi age, he wrote, \u201cWith the aid of electronic computers, the composer becomes a sort of pilot: he presses buttons, introduces coordinates, and supervises the controls of a cosmic vessel sailing in the space of sound, across sonic constellations and galaxies that he could formerly glimpse only in a distant dream. [...] Xenakis\u2019s approach, which led to the Stochastic Music Programme (henceforth SMP) and radically new pieces (such as Pithoprakta , 1956), used formulae originally developed by scientists to explain the behavior of gas particles (Maxwell\u2019s and Boltzmann\u2019s Kinetic Theory of Gases). He saw his stochastic compositions as clouds of sound, with individual notes as the analogue of gas particles. [...] His Eonta (1963\u20131964) for two trumpets, three tenor trombones, and piano was composed with SMP. The program was applied in particular to the creation of the massively complex opening piano solo. COMPOSERS: KOENIG Koenig saw transcription (from computer output to musical score) as an important part of the process of algorithmic composition, writing, \"Neither the histograms nor the connection algorithm contains any hints about the envisaged, \u2018unfolded\u2019 score, which consists of instructions for dividing the labor of the production changes mode, that is, the division into performance parts. The histogram, unfolded to reveal the individual time and parameter values, has to be split up into voices.\" THE CONTEMPORARY LANDSCAPE: A DIVISION BETWEEN COMPOSERS AND AI RESEARCHERS Contemporary (late 20th century) techniques tend to be hybrids of deterministic and stochastic approaches. Systems using techniques from artificial intelligence (AI) and/or linguistics.. [...] While naturally significant to AI research, linguistics, and computer science, such systems tend to be of limited use to composers writing music in a modern and personal style that perhaps resists codification because of its notational and sonic complexity and, more simply, its lack of sufficient and stylistically consistent data [...] Thus we can witness a division between composers concerned with creating new music with personalized systems and researchers interested in developing systems for machine learning and AI. The latter may quite understandably find it more useful to generate music in well-known styles not only because there is extant data but also because familiarity of material simplifies some aspects of the assessment of results. Naturally though, more collaboration between composers and researchers could lead to fruitful, aesthetically progressive results. ALGORITHMIC COMPOSITION OUTSIDE ACADEMIA: BRIAN ENO Application of algorithmic-composition techniques is not restricted to academia or to the classical avant garde. Pop/ambient musician Brian Eno (1948\u2013) is known for his admiration and use of generative systems in Music for Airports (1978) [ wiki | video ] and other pieces. Eno was inspired by the American minimalists , in particular Steve Reich (1936\u2013) and his tape piece It\u2019s Gonna Rain (1965) [ wiki | video ]. [...] Eno said about his Discreet Music (1975) [ wiki | video ], \"Since I have always preferred making plans to executing them, I have gravitated towards situations and systems that, once set into operation, could create music with little or no intervention on my part. That is to say, I tend towards the roles of planner and programmer, and then become an audience to the results\". LIGETI ON THE RELATION BETWEEN MUSIC AND MATHEMATICS After leaving his native Hungary in the late 1950s, Ligeti worked in the same studios as Cologne electronic music pioneers Karlheinz Stockhausen and Gottfried Michael Koenig though produced little electronic music of his own. However, his interest in science and mathematics led to several instrumental pieces influenced by, for example, fractal geometry and chaos theory. But these influences did not lead to a computer-based algorithmic approach. He was quoted in Steinitz saying, \"Somewhere underneath, very deeply, there\u2019s a common place in our spirit where the beauty of mathematics and the beauty of music meet. But they don\u2019t meet on the level of algorithms or making music by calculation. It\u2019s much lower, much deeper\u2014or much higher, you could say.\" EXAMPLE: AN ALGORITHMIC MODEL OF LIGETI'S DESORDRE I have implemented algorithmic models of the first part of D\u00e9sordre in the open-source software system Pure Data , which, along with the following discussion, is based on analyses by Tobias Kunze,26 used here with permission, and Hartmut Kinzler. It is freely downloadable from my Web site http://www.michael-edwards.org/software/desordre.zip [...] The main argument of D\u00e9sordre consists of foreground and background textures.. [...] In D\u00e9sordre we experience a clear, compelling, yet not entirely predictable musical development of rhythmic acceleration coupled with a movement from the middle piano register to the extremes of high and low, all expressed through two related and repeating melodic cycles with slightly differing lengths resulting in a combination that dislocates and leads to metrical disorder. I invite the reader to investigate this in more detail by downloading my software implementation. ON THE NEGATIVE RECEPTION OF ALGORITHMIC COMPOSITION There has been (and still is) considerable resistance to algorithmic composition from all sides, from musicians to the general public. This resistance bears comparison to the reception of the supposedly overly mathematical serial approach introduced by the composers of the Second Viennese School of the 1920s and 1930s. Alongside the techniques of other music composed from the beginning of the 20th century onward, the serial principle itself is frequently considered to be the reason the music\u2014so-called modern music, though now close to 100 years old \u2014 may not appeal. [...] Algorithmic composition is often viewed as a sideline in contemporary musical activity, as opposed to a logical application and incorporation of compositional technique into the digital domain. Without wishing to imply that instrumental composition is in a general state of stagnation, if the computer is the universal tool, there is surely no doubt that not applying it to composition would be, if not exactly an example of Luddism, then at least to risk missing important aesthetic developments that only the computer can facilitate, and that other artistic fields already take advantage of. COMPOSING USING ALGORITHMIC METHODS: MISCONCEPTIONS Much of the resistance to algorithmic composition that persists to this day stems from the misguided bias that the computer, not the composer, composes the music. In the vast majority of cases where the composer is also the programmer, this is simply not true. As composer and computer musician Curtis Roads pointed out more than 15 years ago, it takes a good composer to design algorithms that result in music that captures the imagination. [...] Furthermore, using algorithmic-composition techniques does not by necessity imply less composition work or a shortcut to musical results; rather, it is a change of focus from note-to-note com- position to a top-down formalization of compositional process. Composition is, in fact, often slowed by the requirement that musical ideas be expressed and their characteristics encapsulated in a highly structured and non-musical general programming language. Learning the discipline of programming is itself a time-consuming and, for some composers, an insurmountable problem.","title":"Article: Algorithmic Composition: Computational Thinking in Music"},{"location":"archive/2011/2011-12-21-using-impromptu-to-visualize-rss-feeds/","tags":["canvas","news","rss","visualization","xml"],"text":"Some time ago I've been experimenting with the processing and display of RSS feeds within Impromptu , and as a result I built a small app that retrieves the news feed from The Guardian online and displays on a canvas. I've had a bit of free time these days, so last night I thought it was time to polish it a little and make it available on this blog (who knows maybe someone else will use it as starting point for another project). There're a thousand improvements that could be done to it still, but the core of the application is there: I packaged it as a standalone app that you can download here . (use the 'show package contents' Finder command to see the source code). The application relies on a bunch of XML processing functions that I found within Impromptu 'examples' folder (specifically, it's the example named 35_objc_xml_lib ). I pruned that a bit so to fit my purposes and renamed it xml_lib.scm. By using that, I created a function that extracts title and url info from the guardian feed: ( load \"xml_lib.scm\" ) ( define feedurl \"http://feeds.guardian.co.uk/theguardian/world/rss\" ) ;; ;; loads the feed and extracts title and url ;; ( define get-articles-online ( lambda () ( let* (( out ' ()) ( feed ( xml:load-url feedurl )) ( titles ( objc:nsarray->list ( xml:xpath ( xml:get-root-node feed ) \"channel/item/title/text()\" ))) ( urls ( objc:nsarray->list ( xml:xpath ( xml:get-root-node feed ) \"channel/item/link/text()\" )))) ( for-each ( lambda ( x y ) ( let (( xx ( objc:nsstring->string x )) ( yy ( objc:nsstring->string y ))) ( set! out ( append out ( list ( list xx yy )))))) titles urls ) out ))) Some feed titles are a bit longish, so I added a utility function formattext that wraps the titles' text if they exceed a predefined length. ( define formattext ( lambda ( maxlength txt posx posy ) ( let (( l ( string-length txt ))) ( if ( > l maxlength ) ( let loop (( i 0 ) ( j maxlength ) ;; comparison value: it decreases at each recursion (except the first one) ( topvalue maxlength )) ;; komodo value : must be equal to j at the beginning ( if ( equal? ( - topvalue i ) j ) ;; the first time ( loop ( + i 1 ) j topvalue ) ( begin ;(print (substring txt (- topvalue i) j)) ( if ( string=? ( substring txt ( - topvalue i ) j ) \" \" ) ( string-append ( substring txt 0 ( - topvalue i )) \"n\" ( substring txt ( - topvalue i ) ( string-length txt ))) ( if ( < i topvalue ) ;;avoid negative indexes in substring ( loop ( + i 1 ) ( - j 1 ) topvalue )))))) txt )))) And here's the main loop : it goes through all the feed items at a predefined speed, and displays it on the canvas using a cosine oscillator to vary the colours a bit. At the end of it I'm also updating 3 global variables that are used for the mouse-click-capturing routine. ( define displayloop ( lambda ( beat feeds ) ( let* (( dur 5 ) ( posx ( random 0 ( - *canvas_max_x* 350 ))) ( posy ( random 10 ( - *canvas_max_y* 150 ))) ( txt ( formattext 40 ( car ( car feeds )) posx posy )) ( dim ;(+ (length feeds) 10)) ( if ( = ( length feeds ) 29 ) 60 ;; if it's the first element of the feed list make it bigger ( random 25 50 ))) ( fill ( if ( = ( length feeds ) 29 ) ' ( 1 0 ( random ) 1 ) ;; if it's the first element of the feed list make it reddish ( list ( random ) 1 ( random ) 1 ))) ( style ( gfx:make-text-style \"Arial\" dim fill ))) ( gfx:clear-canvas ( *metro* beat ) *canvas* ( list ( cosr . 5 . 6 . 001 ) 0 ( cosr . 5 . 6 . 001 ) . 5 )) ( gfx:draw-text ( *metro* beat ) *canvas* txt style ( list posx posy )) ( set! *pos_x* posx ) ( set! *pos_y* posy ) ( set! *current_url* ( cadr ( car feeds ))) ( callback ( *metro* ( + beat ( * 1 /2 dur ))) 'displayloop ( + beat dur ) ( if-cdr-notnull feeds ( get-articles-online )))))) In order to capture the clicks on the feed titles I simply create a rectangle path based on the x,y coordinates randomly assigned when displaying the title on the canvas. These coordinates are stored in global variables so that they can be updated constantly. ( io:register-mouse-events *canvas* ) ( define io:mouse-down ( lambda ( x y ) ( print x y ) ( when ( gfx:point-in-path? ( gfx:make-rectangle *pos_x* *pos_y* 200 200 ) x y ) ( util:open-url *current_url* )))) Finally, the util:open-url opens up a url string in your browser (I've already talked about it here ). You can see all of this code in action by downloading the app and taking a look its contents (all the files are under Contents/Resources/app). If I had the time\u2026 \u00b6 Some other things it'd be nice to do: Creating a routine that makes the transitions among feed items less abrupt , maybe by using canvas layers. Refining the clicking events creation: now you can click only on the most recent title; moreover the clicking event handler is updated too quickly, thus unless you click on the titles as soon as it appears you won't be able to trigger the open-url action. Refining the xml-tree parsing function, which now is very very minimal. We could extract news entries description and other stuff that can make the app more informative. Adding some background music to it.","title":"Using Impromptu to visualize RSS feeds"},{"location":"archive/2011/2011-12-21-using-impromptu-to-visualize-rss-feeds/#if-i-had-the-time","text":"Some other things it'd be nice to do: Creating a routine that makes the transitions among feed items less abrupt , maybe by using canvas layers. Refining the clicking events creation: now you can click only on the most recent title; moreover the clicking event handler is updated too quickly, thus unless you click on the titles as soon as it appears you won't be able to trigger the open-url action. Refining the xml-tree parsing function, which now is very very minimal. We could extract news entries description and other stuff that can make the app more informative. Adding some background music to it.","title":"If I had the time\u2026"},{"location":"archive/2011/2011-12-26-article-thought-and-performance-live-coding-music-explained-to-anyone/","tags":["article","livecoding"],"text":"I bookmarked this article on createdigitalmusic.com a while ago (it's from Jul 2010) and ran into it again today.. \" Thought and Performance, Live Coding Music, Explained to Anyone \u2013 Really \" by Peter Kirn contains several simple but thought provoking ideas about livecoding and its relevance in the (traditional) music world. Is livecoding an elitarian activity? Secrets such as why the programming language Lisp inspires religious devotion, or how someone in their right mind would ever consider programming onstage as a form of musical performance, represent the sort of geekery that would seem to be the domain of an elite. Commenting on Ramsay's video ( Algorithms are Thoughts, Chainsaws are Tools ): I doubt very seriously that live coding is the right performance medium for all computer musicians. [..] But Ramsay reveals what live coding music is. It\u2019s compositional improvisation , and code simply lays bare the workings of the compositional mind as that process unfolds. Not everyone will understand the precise meaning of what they see, but there\u2019s an intuitive intimacy to the odd sight of watching someone type code. It\u2019s honest; there\u2019s no curtain between you and the wizard. An interesting comment from a reader puts forward what I'd call the ' livecoding as a programming-virtuosism view: The live coding thing is clearly an amazing talent. I admire anyone who can do that, but it does seem pretty much a sophisticated parlor trick unless the music resulting can stand on its own. The question becomes, were you to hear the piece without observing the live coding performance, would it stand up, or is the quality of the piece augmented by the way in which it was composed ? Is a decent painting painted by someone who paints blindfolded something I would rather see than an excellent painting by someone who paints in a conventional fashion? Cause unless the live coder can spin something up that I would enjoy listening to on my portable media player, I feel like music takes a back seat to the musician, which is a truly peculiar something. [\u2026] This is not to say live coding is something to be ignored, but where from ever in history have we asked this question? Does the musician matter more than the music ? And another, even more critical comment: It is not about letting the audience in at all . It's about cultivating an stage presence of virtuosic technical wizardry. No one in the audience understands the code and that's why everyone marvels at the \"magic\". Worse still it's Lisp, a particularly archaic and obfuscated computer language. So what? \u00b6 I think this is all very useful to read, as it shows what non-specialists may think of livecoding. I've been asking myself similar questions a lot of times, but never really reached a clear conclusion. Is livecoding a music making activity, or is it just programming wizardry? I personally got into livecoding as a musician, first, and only afterwards as a programmer . As a result I tend to see it as some sort of advanced music-making tool. However, interestingly enough, in order to make that tool match my music taste and composition style I had to become an expert at programming the livecoding environment. While doing that, I sort of lost the closure to the 'instrument', which is something you'd have all the time if you play a piano or a guitar. With no closure, you end up in the role of 'music programmer', worrying about mathematical structures and time recursions rather than notes and feelings . It's a cyclical process, actually. You gain competency with some programming pattern that lets you express your musical ideas quickly and efficiently. Then you think of different ideas, but you can't put them into code easily, so you've got to step back, abandon the musical dimension temporarily, and hack some new programming structures. Which makes me think: maybe that's what's so cool about it . Livecoding environments are malleable meta-instruments that let you create (software) music instruments. So the music - the end result - is definitely part of it. But the process, the how in the music creation business is also what we have in focus here . In fact this process is also eminently creative (and here lies the difference with many other digital music 'creation' tools) and, maybe most importantly, this process is so abstracted and codified that it feels as if it represented some sort of essence of creativity.","title":"Article: Thought and Performance, Live Coding Music, Explained to Anyone"},{"location":"archive/2011/2011-12-26-article-thought-and-performance-live-coding-music-explained-to-anyone/#so-what","text":"I think this is all very useful to read, as it shows what non-specialists may think of livecoding. I've been asking myself similar questions a lot of times, but never really reached a clear conclusion. Is livecoding a music making activity, or is it just programming wizardry? I personally got into livecoding as a musician, first, and only afterwards as a programmer . As a result I tend to see it as some sort of advanced music-making tool. However, interestingly enough, in order to make that tool match my music taste and composition style I had to become an expert at programming the livecoding environment. While doing that, I sort of lost the closure to the 'instrument', which is something you'd have all the time if you play a piano or a guitar. With no closure, you end up in the role of 'music programmer', worrying about mathematical structures and time recursions rather than notes and feelings . It's a cyclical process, actually. You gain competency with some programming pattern that lets you express your musical ideas quickly and efficiently. Then you think of different ideas, but you can't put them into code easily, so you've got to step back, abandon the musical dimension temporarily, and hack some new programming structures. Which makes me think: maybe that's what's so cool about it . Livecoding environments are malleable meta-instruments that let you create (software) music instruments. So the music - the end result - is definitely part of it. But the process, the how in the music creation business is also what we have in focus here . In fact this process is also eminently creative (and here lies the difference with many other digital music 'creation' tools) and, maybe most importantly, this process is so abstracted and codified that it feels as if it represented some sort of essence of creativity.","title":"So what?"},{"location":"archive/2012/2012-01-13-special-issue-of-cmj-dvd-on-livecoding/","tags":["academic","dvd","journal","livecoding"],"text":"The latest issue of the Computer Music Journal is now available, and it includes a DVD full of livecoding bonanza. Because this is the Winter issue , it includes the annual CMJ DVD, whose program notes appear near the end of the issue. The curators for the compositions on this year\u2019s DVD are specialists in live coding, the practice of onstage computer programming whose real-time output is an improvised and often collaborative musical performance. As always, the DVD also includes sound and video examples to accompany recent articles, as well as related files on the DVD-ROM portion of the disc. A full description of the contents of the DVD is available here (and here if you're not benefitting from an academic subscription), and I'm very proud to say that it includes also one of my livecoding pieces, Untitled 12 , performed live at the Anatomy Museum livecoding event in 2010.","title":"Special issue of CMJ DVD on livecoding"},{"location":"archive/2012/2012-03-09-composing-at-the-metalevel/","tags":["algorithmiccomposition","books","composition","lisp","taube"],"text":"I've started reading \" Notes from the Metalevel: An Introduction to Computer Composition \", by Heinrich Taube, and realised I should have done that a long time ago! Notes From the Metalevel is a practical introduction to computer composition. It is primarily intended for student composers interested in learning how computation can provide them with a new paradigm for musical composition. I happened to have a pdf version of the book, but the good news is that there's an html version of it too, which includes also all the midi files of the numerous examples included in the book. So make sure you check that out, if you're interested in computer-based composition. You might also be interested in this review on computer music journal , and this course materials from Taube's class at Illinois. The preface to the fist chapter contains this suggestive excerpt from Leonard Schlain's book, The Alphabet Versus the Goddess , which Taube (page 19-20) uses as a metaphor of what algorithmic composition (i.e., metalevel composition) is:: \" The one crowded space in Father Perry's house was his bookshelves. I gradually came to understand that the marks on the pages were trapped words. Anyone could learn to decipher the symbols and turn the trapped words loose again into speech. The ink of the print trapped the thoughts; they could no more get away than a doomboo could get out of a pit. When the full realization of what this meant flooded over me, I experienced the same thrill and amazement as when I had my first glimpse of the bright lights of Konakry. I shivered with the intensity of my desire to learn to do this wondrous thing myself. \" (spoken by Prince Modupe, a west African prince who learned to read as an adult) It is impossible to know exactly how Prince Modupe felt when he discovered a process by which his very thoughts could be trapped and released at will again into speech. But I think his epiphany must be close to what I experienced when, as a young composer, I was first shown how I could use a computer to represent my musical ideas and then \"release them\" into musical compositions. At that instant it became clear to me that there was an entire level of notation above the scores that I had been writing in my regular composition classes, a level I knew nothing about! But I could see that in this level it was possible to notate my compositional ideas in a precise manner and work with them in an almost physical way, as \"trapped words\" that could be unleashed into musical sound whenever I wanted. So what does it meant to compose at the meta level? Given the existence of the acoustic and score representations one might ask if there is yet another representation that constitutes a level of abstraction above the performance score? The answer, of course, is yes; it is what this book terms the metalevel. If the score represents the composition then the metalevel represents the composition of the composition . A metalevel representation of music is concerned with representing the activity, or process, of musical composition as opposed to its artifact, or score. This book is about using the computer to instantiate this level : to define, model and represent the compositional processes, formalism and structures that are articulated in a musical score and acoustic performance but are not literally represented there. By using a computer the composer can work with an explicit metalevel notation, or language, that makes the metalevel as tangible as the performance and acoustic levels .","title":"Composing at the metalevel"},{"location":"archive/2013/2013-02-20-a-metronome-object-for-impromptu/","tags":["impromptu","livecoding","metronome"],"text":"The make-metroclick function returns a closure that can be called with a specific time in beats, so that it plays a sound for each beat and marks the downbeat using a different sound. Possibly useful in order to keep track of the downbeats while you compose, or just to experiment a little with some rhythmic figures before composing a more complex drum kit section. Here's a short example of how to use it: Make-metronome relies on the standard libraries that come with Impromptu, in particular make-metro, which is described in this tutorial e and on this video . Essentially, it requires you to define a metro object first, e.g. (define *metro* (make-metro 120)). Here's the source code:","title":"A metronome object for Impromptu"},{"location":"archive/2013/2013-09-15-building-a-master-volumes-ui-in-impromptu/","tags":["impromptu","volume"],"text":"Based on one of the examples packaged with Impromptu , I wrote a simple function that uses the objc bridge to create a bare-bones user interface for adjusting your audio instruments master volumes. The script assumes that your audio graph includes a mixer object called *mixer*. The UI controllers are tied to that mixer's input buses gain value. The objc bridge commands are based on the silly-synth example that comes with the default impromptu package. Being able to control volumes manually rather than programmatically made a great difference for me. Both in live coding situations and while experimenting on my own, it totally speeds up the music creation process and the ability of working with multiple melodic lines. The next step would be to add a midi bridge that lets you control the UI using an external device, in such a way that the two controllers are kept in sync too. Enjoy! P.s.: this is included in the https://github.com/lambdamusic/ImpromptuLibs","title":"Building a master volumes UI with impromptu"},{"location":"archive/2013/2013-11-27-new-livecoding-screencast-ziggurat-51/","tags":["livecoding"],"text":"So hard to find time to do something creative these days. So I thought I'd post a screencast of a livecoded piece I'm still working on: Ziggurat 51 . Hope you'll find it interesting! In the video I'm using the mixer UI I've previously talked about here . I quite like it, as you can see it's so much easier to focus on composition and performance by not having to worry about volumes in the code! Also, since Impromptu's video recording functionality is broken on the latest versions of OSx, I've been testing out a new software called Screenflick , which is actually pretty good (apart from the logo you can't get rid of unless you buy the software). Enjoy!","title":"New livecoding screencast: Ziggurat 51"},{"location":"archive/2015/2015-05-06-impromptu-language-documentation-back-online/","tags":["impromptu"],"text":"For all Impromptu aficionados: a little online application that can be used to search&browse the language documentation: http://hacks.michelepasin.org/impromptu/ Impromptu is a scheme -based OSX programming language and environment for composers, sound artists, VJ\u2019s and graphic artists with an interest in live or interactive programming. As part of its original website, Impromptu included a wiki containing documentation and examples. Unfortunately the wiki isn't available online anymore, which is a real shame so the other day I've decided to replace it with a simple searchable index of the programming language functions. This is based on the documentation file coming with the latest Impromptu release (2.5); so, in theory, it shouldn't be too different from the original wiki site. For those of you who are new to all of this, it's worth mentioning that Impromptu is now being superseded by the Extempore programming language. Extempore is much more solid and feature rich; also, it is less dependent on the OS X platform APIs. Still, many of the original Impromptu scheme functions are still available, so this documentation could turn out to be useful too. Enjoy!","title":"Impromptu language documentation back online!"},{"location":"archive/2020/2020-11-02-livecoding-piano-scales/","tags":["algorithmiccomposition","extempore"],"text":"A new livecoding composition using Extempore and Ableton Live: 'Piano Scales'. Algorithmic compositions using piano instruments always strike me for their captivating simplicity. So here's a new little experiment, titled 'Piano Scales '. Repeated scales with a touch of randomness \u00b6 The gist of this musical algorithm is amazingly simple. Pick a scale. You play it using a variable time-interval between its notes, which is determined by a cosine function ( cosr ). The variable interval gives the final result a touch of suspense and makes it less computer-like. After each note, more notes are played programmatically, after brief (random) intervals of half a beat, or 3/2 of a beat. Fifths, octaves, minor sevenths... as you please. This whole thing repeating itself, at each iteration of the loop though the sound volume gets quieter by a fixed amount. Eventually, when the volume goes to 0, the repetition stops. ( define xsc ( lambda ( beat vel scale ) ( let (( dur ( cosratio 4 2 1 /128 ))) ;; piano ( play ( car scale ) vel dur 1 ) ( play 5 ( + 12 ( car scale )) 1 ( * dur 2 ) 1 ) ( play ( oneof 3 /2 2 ) ( + 24 ( car scale )) 1 ( * dur 2 ) 1 ) ;; bass ( play 5 ( car scale ) 90 ( * dur 2 ) 2 ) ( :chance . 8 ( play 6 ( + ( car scale ) 2 ) 90 ( * dur 2 ) 2 )) ;; repeat ( set! scale ( rotate scale -1 )) ( set! vel ( - vel 1 )) ( if ( > vel 0 ) ( callback ( *metro* ( + beat ( * 1 /2 dur ))) 'xsc ( + beat dur ) vel scale ))))) ;; set scale to play so that scales overlap with each other ( xsc ( *metro* 'get-beat 1 ) 50 ; vol ( :mkscale c1 'pentatonic 2 )) ;; run again with 'ionian, 'aeolian etc.. for interesting harmonic effects The full source code on GitHub . About Extempore \u00b6 Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world. Algorithmic composition is the technique of using algorithms to create music.","title":"Livecoding composition: 'Piano Scales' (Extempore + Ableton Live)"},{"location":"archive/2020/2020-11-02-livecoding-piano-scales/#repeated-scales-with-a-touch-of-randomness","text":"The gist of this musical algorithm is amazingly simple. Pick a scale. You play it using a variable time-interval between its notes, which is determined by a cosine function ( cosr ). The variable interval gives the final result a touch of suspense and makes it less computer-like. After each note, more notes are played programmatically, after brief (random) intervals of half a beat, or 3/2 of a beat. Fifths, octaves, minor sevenths... as you please. This whole thing repeating itself, at each iteration of the loop though the sound volume gets quieter by a fixed amount. Eventually, when the volume goes to 0, the repetition stops. ( define xsc ( lambda ( beat vel scale ) ( let (( dur ( cosratio 4 2 1 /128 ))) ;; piano ( play ( car scale ) vel dur 1 ) ( play 5 ( + 12 ( car scale )) 1 ( * dur 2 ) 1 ) ( play ( oneof 3 /2 2 ) ( + 24 ( car scale )) 1 ( * dur 2 ) 1 ) ;; bass ( play 5 ( car scale ) 90 ( * dur 2 ) 2 ) ( :chance . 8 ( play 6 ( + ( car scale ) 2 ) 90 ( * dur 2 ) 2 )) ;; repeat ( set! scale ( rotate scale -1 )) ( set! vel ( - vel 1 )) ( if ( > vel 0 ) ( callback ( *metro* ( + beat ( * 1 /2 dur ))) 'xsc ( + beat dur ) vel scale ))))) ;; set scale to play so that scales overlap with each other ( xsc ( *metro* 'get-beat 1 ) 50 ; vol ( :mkscale c1 'pentatonic 2 )) ;; run again with 'ionian, 'aeolian etc.. for interesting harmonic effects The full source code on GitHub .","title":"Repeated scales with a touch of randomness"},{"location":"archive/2020/2020-11-02-livecoding-piano-scales/#about-extempore","text":"Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world. Algorithmic composition is the technique of using algorithms to create music.","title":"About Extempore"},{"location":"archive/2020/2020-11-23-a-new-livecoding-project-the-musical-code/","tags":["algorithmiccomposition","extempore","github","impromptu"],"text":"I've started a new livecoding project on Github called The Musical Code . Plan is to add experimental musical code/algorithms created via the amazing Extempore programming language (as well as it precursor Impromptu ). Background: I have accumulated so much musical-code ideas over the years... so I've finally resolved to clean it up, reorganise it and publish it somewhere. Github seemed the best option, these days. Code + Video \u00b6 I soon realised that just the code by itself won't do it . Especially considering that the environments I used to 'run it' (and to make it go 'beep') could rapidly disappear: become obsolete, or get out of fashion! Hence there's a YouTube channel as well, where one can find a screencast recording of each of the 'musical codes'.","title":"'The Musical Code' on GitHub"},{"location":"archive/2020/2020-11-23-a-new-livecoding-project-the-musical-code/#code-video","text":"I soon realised that just the code by itself won't do it . Especially considering that the environments I used to 'run it' (and to make it go 'beep') could rapidly disappear: become obsolete, or get out of fashion! Hence there's a YouTube channel as well, where one can find a screencast recording of each of the 'musical codes'.","title":"Code + Video"},{"location":"archive/2020/2020-12-12-extempore-and-ableton-live/","text":"\"computermusic\" tags: \"algorithmiccomposition\" \"extempore\" review: true Here are the basic steps to connect Extempore to Ableton LIVE, so to have a masterclass DAW at your (literally) fingertips. TODO - fix date - get main points from https://groups.google.com/g/extemporelang/c/9cQqmflEdpY/m/vej0rEw-AQAJ Why? \u00b6 Main steps \u00b6 Advanced: setting up MIDI defaults \u00b6 What is Extempore? \u00b6 Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world.","title":"2020 12 12 extempore and ableton live"},{"location":"archive/2020/2020-12-12-extempore-and-ableton-live/#why","text":"","title":"Why?"},{"location":"archive/2020/2020-12-12-extempore-and-ableton-live/#main-steps","text":"","title":"Main steps"},{"location":"archive/2020/2020-12-12-extempore-and-ableton-live/#advanced-setting-up-midi-defaults","text":"","title":"Advanced: setting up MIDI defaults"},{"location":"archive/2020/2020-12-12-extempore-and-ableton-live/#what-is-extempore","text":"Extempore is a programming language and runtime environment designed by Andrew Sorensen to support livecoding and cyberphysical programming, where a human programmer operates as an active agent in the world.","title":"What is Extempore?"},{"location":"archive/2021/2021-01-22-the-kryos-noise-is-available-on-spotify/","tags":["music","progrock","rock","spotify"],"text":"The prog rock album I've worked on years ago with the band Kryos Project is now available also on Spotify (and Amazon too). Why? Well it just feels good to be able to open up Spotify and listen to your own music. This is stuff we've made almost 20 years ago (!) but it still feels kinda relevant. Fresh. Well.. you know what I mean. Check out The Kryos' Noise on Spotify . Cool. How do I get my band too on Spotify? \u00b6 It was surprisingly easy actually, if you don't mind spending a little money (around 20 dollars per year). I used Distrokid to handle the distribution to all major services. It's a bit fiddly to work with and the overall UX is rather barebones, but it does what is supposed to for a pretty damn honest price! A handy walkthough guide can be found here .","title":"'The Kryos Noise' is available on Spotify"},{"location":"archive/2021/2021-01-22-the-kryos-noise-is-available-on-spotify/#cool-how-do-i-get-my-band-too-on-spotify","text":"It was surprisingly easy actually, if you don't mind spending a little money (around 20 dollars per year). I used Distrokid to handle the distribution to all major services. It's a bit fiddly to work with and the overall UX is rather barebones, but it does what is supposed to for a pretty damn honest price! A handy walkthough guide can be found here .","title":"Cool. How do I get my band too on Spotify?"},{"location":"archive/2021/2021-02-01-extempore-functions-explorer-updated-to-latest-release-v0-8-7/","tags":["algorithmiccomposition","extempore"],"text":"The Extempore functions explorer has been updated with the latest version of the Extempore programming language: v0.8.9 Try it out at: https://extempore.michelepasin.org/ About the explorer app \u00b6 The Extempore functions explorer is a little Django webapp I built a while ago in order to make it easier to browse (and learn about) the Extempore programming language. The source code is available on Github.","title":"Extempore functions explorer updated to latest release (v0.8.9)"},{"location":"archive/2021/2021-02-01-extempore-functions-explorer-updated-to-latest-release-v0-8-7/#about-the-explorer-app","text":"The Extempore functions explorer is a little Django webapp I built a while ago in order to make it easier to browse (and learn about) the Extempore programming language. The source code is available on Github.","title":"About the explorer app"},{"location":"archive/2021/2021-04-10-livecoding-rhythmic-cycles/","tags":["algorithmiccomposition","extempore"],"text":"A new livecoding composition using Extempore and Ableton Live: 'Rhythmic Cycles'. Using 'map' to trigger repeated notes \u00b6 The gist of this experiment rotates around the map function. A seed list of notes, and one of offsets , is used to generate musical play sequences: ( map ( lambda ( x y z ) ( onbeat x 0 ( play y z ( * dur . 9 ) 1 )) ) times notes volumes ) This technique generates a texture of sounds with a touch of randomness. If the pattern above gets repeated, changing the input parameters periodically leads to the generation of very interesting musical patterns. For example: times can be shifted up or down by 1/4 beat or so notes can be transposed using different chord structures volumes can use cyclical variations eg a cosine function The end result reminds me of a hypnotical tune that keeps repeating but it's never exactly the same. Similar to 8-bit video game music patterns, but obviously when using more interesting sounds/instruments to begin with, the end result is more engaging too. Source code \u00b6 The full source code can be found on Github . ( define notes ( list c3 g3 bb3 )) ( define times ( :mklist 8 ( oneof 1/2 1/4 ))) ( define inc ( lambda ( alist ) ( map ( lambda ( x ) ( if ( < x 1 ) ( ifr .7 ( add 1/4 x ) x ) 0 ) ) alist ) )) ( define lp1 ( lambda ( beat ) ( let (( dur 1/16 ) ( v1 ( cosr ( cosr 50 18 1/64 ) 30 1/64 )) ( v2 ( cosr ( cosr 50 18 1/150 ) 30 1/40 )) ( fc 8 )) ( println v1 v2 ) ( onbeat 4 0 ( set! times ( inc times ))) ( onbeat 32 0 ( if ( < v1 40 ) ( set! notes ( rotate notes -1 )))) ( map ( lambda ( x y z ) ( onbeat x 0 ( play y z ( * dur .9 ) 1 )) ( onbeat x 0 ( play y z ( * dur .9 ) 3 )) ) ( slice fc times ) ( slice fc ( :mkchord ( car notes ) '-6 8 )) ( slice fc ( list v1 v2 v1 v2 v1 v2 v1 v2 )) ) ( callback ( *metro* ( + beat ( * 1/2 dur ))) 'lp1 ( + beat dur ))))) ( lp1 ( *metro* 'get-beat 1 ))","title":"New livecoding composition: 'Rhythmic Cycles' with Extempore"},{"location":"archive/2021/2021-04-10-livecoding-rhythmic-cycles/#using-map-to-trigger-repeated-notes","text":"The gist of this experiment rotates around the map function. A seed list of notes, and one of offsets , is used to generate musical play sequences: ( map ( lambda ( x y z ) ( onbeat x 0 ( play y z ( * dur . 9 ) 1 )) ) times notes volumes ) This technique generates a texture of sounds with a touch of randomness. If the pattern above gets repeated, changing the input parameters periodically leads to the generation of very interesting musical patterns. For example: times can be shifted up or down by 1/4 beat or so notes can be transposed using different chord structures volumes can use cyclical variations eg a cosine function The end result reminds me of a hypnotical tune that keeps repeating but it's never exactly the same. Similar to 8-bit video game music patterns, but obviously when using more interesting sounds/instruments to begin with, the end result is more engaging too.","title":"Using 'map' to trigger repeated notes"},{"location":"archive/2021/2021-04-10-livecoding-rhythmic-cycles/#source-code","text":"The full source code can be found on Github . ( define notes ( list c3 g3 bb3 )) ( define times ( :mklist 8 ( oneof 1/2 1/4 ))) ( define inc ( lambda ( alist ) ( map ( lambda ( x ) ( if ( < x 1 ) ( ifr .7 ( add 1/4 x ) x ) 0 ) ) alist ) )) ( define lp1 ( lambda ( beat ) ( let (( dur 1/16 ) ( v1 ( cosr ( cosr 50 18 1/64 ) 30 1/64 )) ( v2 ( cosr ( cosr 50 18 1/150 ) 30 1/40 )) ( fc 8 )) ( println v1 v2 ) ( onbeat 4 0 ( set! times ( inc times ))) ( onbeat 32 0 ( if ( < v1 40 ) ( set! notes ( rotate notes -1 )))) ( map ( lambda ( x y z ) ( onbeat x 0 ( play y z ( * dur .9 ) 1 )) ( onbeat x 0 ( play y z ( * dur .9 ) 3 )) ) ( slice fc times ) ( slice fc ( :mkchord ( car notes ) '-6 8 )) ( slice fc ( list v1 v2 v1 v2 v1 v2 v1 v2 )) ) ( callback ( *metro* ( + beat ( * 1/2 dur ))) 'lp1 ( + beat dur ))))) ( lp1 ( *metro* 'get-beat 1 ))","title":"Source code"},{"location":"archive/2022/2022-04-07-cellos-livecoding/","tags":["algorithmiccomposition","extempore"],"text":"A new livecoding composition using Extempore and Ableton Live: 'Study for Cello and Double-bass'. Creating chords using a cosine function \u00b6 The main technique used in this piece is to generate chord/harmonic variations using a cosine functions. ( at 8 0 ( set! *melody* ( :mkchord ( :mkint 48 ( cosrfloor 7 7 1 /30 ) 'M ) 'M ( cosrfloor 7 3 1 /5 )) ) Every 8 beats the root chord (used by all instruments in order to generate musical patterns) gets updated. Two cosine functions are used to simultaneously: Determine the amplitude of the interval (major or minor, starting from C3) that generates the root note of the chord. Determine the number of notes in the chord. The two cosine functions have different frequencies, leading to a variety of combinations of chord shapes that keep cycling around. Full source code \u00b6 ( define *melody* ( mkchord 48 '- )) ( define *durs* ( list 1 /2 1 /2 1 1 /2 )) ( define loop ( lambda ( beat melody durs ) ( let (( dur ( car durs )) ( p ( car melody ))) ( at 8 0 ( set! *melody* ( :mkchord ( :mkint 48 ( cosrfloor 7 7 1 /30 ) 'M ) 'M ( cosrfloor 7 3 1 /5 )) ) ( play cello ( octave ( car *melody* ) 3 4 ) 60 8 ) ( play 2 strings ( octave ( :mkint ( car *melody* ) 3 'M ) 7 9 ) 50 8 ) ( play 5 /2 strings ( octave ( :mkint ( car *melody* ) 5 ) 3 5 ) 40 6 ) ( play 4 strings ( octave ( :mkint ( car *melody* ) 12 ) 7 9 ) 30 4 ) ) ( play pluck p 60 ( * dur . 9 ) ) ( play 3 /2 pluck ( add -12 p ) 60 ( * dur . 9 ) ) ( at 4 0 ( play pluck ( :mkint p ( oneof 12 4 5 ) ) 50 ( * dur 2 ) ) ( play ( oneof 1 1 /2 ) pluck ( :mkint p 24 ) 40 ( * dur 2 ) ) ) ( callback ( *metro* ( + beat ( * 1 /2 dur ))) 'loop ( + beat dur ) ( cdr-or-else melody *melody* ) ( cdr-or-else durs *durs* ))))) ( loop ( *metro* 'get-beat 1 ) *melody* *durs* ) Also available on GitHub .","title":"Composition: 'Study for Cello and Double-bass'"},{"location":"archive/2022/2022-04-07-cellos-livecoding/#creating-chords-using-a-cosine-function","text":"The main technique used in this piece is to generate chord/harmonic variations using a cosine functions. ( at 8 0 ( set! *melody* ( :mkchord ( :mkint 48 ( cosrfloor 7 7 1 /30 ) 'M ) 'M ( cosrfloor 7 3 1 /5 )) ) Every 8 beats the root chord (used by all instruments in order to generate musical patterns) gets updated. Two cosine functions are used to simultaneously: Determine the amplitude of the interval (major or minor, starting from C3) that generates the root note of the chord. Determine the number of notes in the chord. The two cosine functions have different frequencies, leading to a variety of combinations of chord shapes that keep cycling around.","title":"Creating chords using a cosine function"},{"location":"archive/2022/2022-04-07-cellos-livecoding/#full-source-code","text":"( define *melody* ( mkchord 48 '- )) ( define *durs* ( list 1 /2 1 /2 1 1 /2 )) ( define loop ( lambda ( beat melody durs ) ( let (( dur ( car durs )) ( p ( car melody ))) ( at 8 0 ( set! *melody* ( :mkchord ( :mkint 48 ( cosrfloor 7 7 1 /30 ) 'M ) 'M ( cosrfloor 7 3 1 /5 )) ) ( play cello ( octave ( car *melody* ) 3 4 ) 60 8 ) ( play 2 strings ( octave ( :mkint ( car *melody* ) 3 'M ) 7 9 ) 50 8 ) ( play 5 /2 strings ( octave ( :mkint ( car *melody* ) 5 ) 3 5 ) 40 6 ) ( play 4 strings ( octave ( :mkint ( car *melody* ) 12 ) 7 9 ) 30 4 ) ) ( play pluck p 60 ( * dur . 9 ) ) ( play 3 /2 pluck ( add -12 p ) 60 ( * dur . 9 ) ) ( at 4 0 ( play pluck ( :mkint p ( oneof 12 4 5 ) ) 50 ( * dur 2 ) ) ( play ( oneof 1 1 /2 ) pluck ( :mkint p 24 ) 40 ( * dur 2 ) ) ) ( callback ( *metro* ( + beat ( * 1 /2 dur ))) 'loop ( + beat dur ) ( cdr-or-else melody *melody* ) ( cdr-or-else durs *durs* ))))) ( loop ( *metro* 'get-beat 1 ) *melody* *durs* ) Also available on GitHub .","title":"Full source code"},{"location":"drafts/","text":"Drafts \u00b6 https://github.com/lukasgeiter/mkdocs-awesome-pages-plugin/#hide-directory Create a file named .pages in a directory and set the hide attribute to true to hide the directory, including all sub-pages and sub-sections, from the navigation: hide: true Note: This option only hides the section from the navigation. It will still be included in the build and can be accessed under its URL","title":"Drafts"},{"location":"drafts/#drafts","text":"https://github.com/lukasgeiter/mkdocs-awesome-pages-plugin/#hide-directory Create a file named .pages in a directory and set the hide attribute to true to hide the directory, including all sub-pages and sub-sections, from the navigation: hide: true Note: This option only hides the section from the navigation. It will still be included in the build and can be accessed under its URL","title":"Drafts"}]}